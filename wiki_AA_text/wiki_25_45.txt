3次元コンピュータグラフィックス
3次元コンピュータグラフィックス（さんじげんコンピュータグラフィックス、）は、コンピュータの演算によって3次元空間内の仮想的な立体物を2次元である平面上の情報に変換することで奥行き感（立体感）のある画像を作る手法である。20世紀末からのコンピュータ技術の急速な発達と性能向上によって、従来は大企業や大きな研究所でしか得られなかった精細で高品質の3次元画像が、21世紀初頭現在ではPCやゲーム機で得られるようになっている。
毎年夏にアメリカ合衆国で開催されるCGの祭典「SIGGRAPH」（シーグラフ）にて、世界中の多くの研究者により最新のCGの論文が発表され、技術更新がなされている。
3DCGは、ユーザが仮想的な視点や対象物の変更を操作して直ちに更新された画像を得るCADのようなシミュレーションやコンピュータゲームのように実時間処理の動画像と、CG映画のように製作者側があらかじめ時間を掛けて動画像を製作しておくもの、そして、静止画の3種類に大別できる。十分に高い技術を用いれば、無生物では実写と見分けがつかないほど遜色のない画像が得られるが、人物画ではCG特有の無機質なものとなることが多く、ロボットでの不気味の谷現象と同じく一般に人の表情を描くのは不得手である。
ユーザーの操作や何らかの観測などの情報入力に対応して即座に映像を生成する処理を指す。
代表的な実時間処理による動画生成の用途はコンピュータゲームである（ムービー）。PCや家庭用ゲーム機からゲームセンターのゲーム機、携帯ゲーム機や部分的には携帯電話でのゲームにまで3DCGを用いた動画像が生成・表示されている。
工業用途では製品の設計段階でCAD/CAMによって部品同士の接続や製品の完成図を描いたり、建築でのパースを描画する目的で利用されている（建築パースの作成では設計図面さえあれば建築イメージを確認できるため、古代遺跡の復元モデルなどをフォトリアリスティックに描画する用途などにも用いられている。立体地図の場合は地形の起伏や大縮尺の場合の建物形状をいろいろな視点から眺められるように用いる）。また、現実世界での運動や周囲状況をコンピュータ・シミュレーションで再現することで効果的な訓練が行える、ドライブシミュレータやフライトシミュレータなども実時間処理での3DCG技術の利用例である。
動画生成における実時間処理はそうでないものに比べて画像の精度よりも実時間内に如何にそれらしい画像を生み出すかが求められるため、ローポリゴンモデルにテクスチャマップで細部を表現するなど、あらゆる箇所で処理を省いて演算をできるだけ少なくて済むように工夫されている。PC用の3DCG動画を生成するための専用ICとしてGPUが登場している。
3DCGによる映画の制作が代表的な「実時間処理ではない」動画生成用途である。多くの映画では、写実的（フォトリアル）な画像を制作する目的や、反対にマンガ的なアニメーションのように非現実的な画像を制作する目的で利用され、実写との合成映像も含めれば大半の商業用映画に何らかの形で3DCGの技術が用いられている。SF映画やアニメ映画などでは長時間の3DCG画像が必要とされることがあり、そのような場合には、3DCG演算専用の多数のコンピュータから構成される「レンダリング・ファーム」と呼ばれるサーバー施設で数ヶ月単位で動画像の生成が行われる。
広告宣伝用途での3DCG動画像も広告製作会社内やメーカー自身の内部で、映画と同じような環境で製作されている（自動車産業が3DCG動画による広告の代表であるが、他の産業でも設計過程でコンピュータ・シミュレーションを必要とする航空宇宙、軍事、船舶といった分野の企業が物理現象のシミュレーションと共に画像表示のための3DCG技術を利用している）。
広告や芸術、そしてあらゆる種類のイラストレーション用途に3DCGを用いた静止画が製作されている。
3次元CGの基本原理は3点座標を持つ対象物を2次元座標の仮想スクリーン上に透視投影することである（元々2次元の画像情報を扱うドローイングでは、せいぜいがシート状の矩形面同士の重なりを考慮するだけで、奥行きによる尺度の違いや照明による陰影の違いを演算する必要はないが、3DCGでは立体物ゆえに無数の座標変換や画素の塗り分けを行わなければならない）。
まず［図1］のような3次元座標をディスプレイ内に考える。原点に視点があるとして座標内の3点の座標を持つ点Aはどのように見えるだろうか。
［図2］のように原点と点Aの間にスクリーンを置いた場合、スクリーン平面上に映し出される点Aの投影座標は h=x*(s/z)、v=y*(s/z) で求められる。zが大きくなれば、スクリーン上の点Aは限りなく原点に近付く。つまり遠くのものは小さく見えるわけである。スクリーンを置く座標sは大きくなればパースが緩く、小さくなればパースがきつくなるので、レンズの画角を表現することが出来る。
これが透視投影の原理であり、3点座標を持つ点をそれぞれ結べばワイヤーフレーム画像が、結んだ点から面を作ればポリゴンによる表現が可能となる。
3DCGの制作は次のような行程にわけることができる。
仮想3次元空間上に個々の物体の形状をつくる。多くの3DCGソフトウェアでは、一つの面を三角形や四角形といった多角形の集合として表現する。三角形しか扱えないソフトウェアも多い（四角形以上は曲面になる可能性があるため）。これらの多角形はポリゴン（英語で多角形の意）と呼ぶ。各形状はポリゴンの集合で表現される。モデリングで作られた形状をモデルやオブジェクトと呼ぶ。
他に面を定義する方法としては自由曲面がある。自由曲面はNURBS曲線、スプライン曲線、ベジェ曲線などで曲面を構成する方法で、ポリゴンのみでモデリングされた形状に比べ滑らかで正確な形状が得られる。ポリゴンのみでモデリングすることを、ポリゴンモデリングと呼んで、自由曲面を利用したモデリングと区別することがある。
形状が出来たら、オブジェクトに材質（マテリアル）を設定する。材質を設定しなければ、オブジェクトはただ一様に光を反射するだけの均質な物体になる。多くの3DCGソフトウェアでは、色、透明度、反射、屈折率、自己発光、バンプ、ディスプレイスメントなどの設定項目がある。
モデリングで制作したオブジェクトを、仮想3次元空間上に配置する。現実世界と同様、光源も配置しなければ何も表示されない(黒一色の画像が出力される)。また、仮想的なカメラを配置することで視点を設定する。これらを配置・設定した仮想的な舞台をシーンと呼ぶ。
レンダリングは、これまでに設定したシーンから、仮想的なカメラに写されるはずの画像を生成する工程である。オブジェクトの形状や位置、光のあたり具合などをコンピュータが計算し、最終的な画像が生成される。レンダリングのアルゴリズムには、それぞれ処理速度や品質の違う多くの種類があり、用途に合わせて使い分ける。各種の設定を済ませレンダリングを開始した後は、レンダリングが終了するまで制作者がすることは特にない。一般にレンダリングには多くの時間を要する。シーン内に多くの形状があったり、高度なレンダリングアルゴリズムを利用している場合、数時間から数日かかる場合もある。ゲームなどリアルタイムにレンダリングしなければならないときは、単純で高速なレンダリングアルゴリズムを適用したり、シーンの総ポリゴン数を少なくするなど、大きな制限が加えられる。映画など大規模な制作現場では、同時に複数のコンピュータにレンダリング処理をさせて、計算時間を短縮することがある。
レンダリング手法によっては空気による遠近法・光の照り返しなども計算される。そういった複雑な計算をするレンダリング処理は専用回路（GPU）で行われることも多い。高い対話性と双方向性が得られるので、ゲームに用いられる場合はこの形態をとる。
レンダリングで得られた画像が、完全に制作者の意図したものになるとは限らない。PhotoshopやAdobe After Effectsなどのフォトレタッチツールなどで、コントラストや色味を手直しすることもある。
3DCGのモデルに画像を貼り付けることをテクスチャマッピング、その貼り付けられる画像をテクスチャという。テクスチャを貼ることにより、モデリングやシェーダーのみでは表現の困難な、モデル表面の細かな色彩情報や質感などを設定することができる。
テクスチャの貼り付け方としては、単純にカメラ方向からモデルにテクスチャを投影するだけの方法や、UV座標によってモデルへのテクスチャの投影を正確に設定する方法がある。カメラ方向からの単純な投影では、動き回るキャラクターのテクスチャがズレることが回避できないため、では、3DCGを扱う者にとって、モデルにはUVをきちんと設定するのが常識である。
反射の強度を設定する反射マッピング、小さな凹凸を擬似的に表現するバンプマッピング／法線マッピング、透明度を設定する透明度マッピングなどがある。形状の表面に画像の情報を加えることによって、表面の模様や質感が表現されて、より現実的な画像になる。ディスプレースメントマッピングのように、画像情報をもとに実際の凹凸形状を動的に生成する手法もある。
特にコンピュータゲームにおいては、リアルタイムで3DCGキャラクターを描画する必要から、極力少ないポリゴンで作成されたモデル（ローポリゴンモデル）に、ディテールや陰影などを描き込んだテクスチャを貼り付ける手法が行われている。
モデルの表面の法線の方向を変化させることによって、擬似的に凹凸を表現する技術。グレースケール画像で元形状に対する高低を定義する。少ないポリゴンで細かな陰影をリアルに表現できる利点があるが、実際に表面に立体的な凹凸があるわけではないので、ズーム時や、面を横から見た場合などに違和感のある画像となる。
は法線の方向（3次元ベクトル）を直接定義する法線マッピング（ノーマルマッピング）も用いられるが、法線マップを手作業で作成するのは困難であるため、通常は高精細モデルのディティールを法線マップに変換して単純化モデルに適用する手法が採られている。
3Dモデルの頂点を実際に表面に対して上下に移動させて凹凸を表現する技術。バンプマッピングに比べて、実際に立体的な凹凸となるため違和感のない画像が得られるが、表現する凹凸に応じてポリゴン数が増大する欠点がある。リアルタイム3DCGの分野ではDirect3D 10およびOpenGL 3.2でジオメトリシェーダーが標準化された後、Direct3D 11/OpenGL 4にてテッセレーションが標準化され、GPUによるディスプレースメントマッピングが可能となった。
バンプマッピングによる凹凸の表現はあくまで擬似的に陰影を表現し、またディスプレースメントマッピングによる凹凸は3Dモデルそのものの頂点を移動させて凹凸を表現するだけであるのに対して、3Dモデルに立体的な濃度関数を掛け合わせることにより、小さな凹凸はもとより、深い溝や貫通した穴のような大きな構造も表現することができる技術。
ポリゴンはあくまで多角形の面なので、モデルにはっきりとした表面が無かったり、モデルの数が膨大であったり、動きが不規則な煙や炎などを表現するのには不向きである。また、毛髪や草木など、ポリゴンで表現しようとするとその量から大変な人的労力やリソースが必要になるものがある。パーティクル (particle) はこれらの問題を解決するための技術である。パーティクルはこれらを微小な粒子の集合として表現し、確率モデルでその動き・形状を処理する。高度なモデリングまたはレンダリングソフトウェアで扱うことができる。これをレンダリングする際にはビルボーディングやメタボールなどの技術が使用される。
大まかにモデリングされたポリゴンメッシュをメモリ上で細分化して、滑らかで継ぎ目の無い形状にする技術。少ないポリゴン数で形状を滑らかに表現できるため、編集や変形も容易になる。ただし、工業用CADなど形状に高い精度が要求されるときには利用できない。
複数のオブジェクトどうしを集合演算する技術。他の形状と結合する（和）、一方の形状から他方の形状を削り取る（差）、重なっている部分のみを形状として抜き出す（積）ことなどができる。
複数の3次元座標上の点を中心として濃度分布を設定し、濃度の閾値を形状の表面とする技術。球状の形状が引き付けあうようにみえる融合と、反発しあうように見える反転融合がある。正確な形状を作ることは難しいが、有機的な形状を少ない制御点で作るのに向いている。3DCG特有の概念ではなく、2Dの画像表現にも使われることもある。当初はその呼び名の通り球体を基本としていたが、その後改良が進められ、球体以外の形状も利用できるようになり、有機的な形状をモデリングする技術として活用されている。
モデリングの他に、流れる液体の表現等にも使われる。レンダリングに必要な計算量は多くともメモリの使用量が少ないのが利点だったが、ではそれらのリソースが充実している上、流体力学の計算法も進歩しているため、映像制作の現場では、見た目のチープなメタボールはほぼ使われることのない技術になっている。
IK (inverse kinematics) は3次元コンピュータグラフィックスの専門用語ではない。もともと力学の一分野であり、ロボティクス等のほうが「本家」である。
人間など多くの関節を持つ動物において、関節の末端部分の位置は常にその親となる部分の位置と角度に依存している。そのため、通常では関節の末端部分の位置を求める場合においてモデルの中心から末端にかけて順番に関節の角度計算をする、という向きが「順方向」である。しかし、その方向で計算したのでは、例えば「机の上を掌でなでるような動き」を実現するのは面倒なものとなる。なぜなら、関節の末端部分の位置の変化を求めるためには複雑な計算をモデルの中心から全て順方向に再計算しなおさなければならないため非常に非効率的だからである。この解決のため、末端部分の位置を先に決めてその関節の末端位置を実現するための親となる関節の角度を、一種の「逆問題」を解くようにして求めることが考えられる。
以上の説明からもわかるように、物理的な運動学に関して一般に考えることができる逆問題的な考え方のひとつである。
股－ひざ－足のような形状を想定してみると、足の裏が自転車のペダルにくっついたままペダルが回転運動をするアニメーションを作る場合に、ペダルの回転運動に合うように股・そしてひざや足の角度の変更を行なっていくのではなく、足部分の移動に追随する形で、逆に足－ひざ－股の順に各関節の動きを順次割りだして決定する方が、見た目も自然なアニメーションが作成できる。
3次元空間上に光源を設定することをライティングと呼ぶ。光源によってモデルは可視物となる。光源には次のような種類がある。
3DCGソフトウェアによっては、球や円柱などの単純なオブジェクト（プリミティブ）を、ポリゴンではなく中心点や半径、高さといった数値で扱う場合がある。これらの細部を編集したりレンダリングする場合は、ポリゴンメッシュに変換する必要がある。これをtessellationと呼ぶ（tessellateはモザイク模様にするという意味）。ただし、オブジェクトが本来持っていた形状情報である球体、円錐などのような抽象的な表現は失われてしまう。
の3DCGにおいて、速度面などの理由により単純化された照明モデル・反射モデルを利用する場合、多くはPhongの反射モデル (Phong reflection model) を採用している。Phong反射モデルは経験則であり、ローカルイルミネーション（局所照明）の代表例である。より写実的なシーンを描画するためには、後述するラジオシティなどのグローバルイルミネーション（大域照明）をサポートする、光学的・物理学的に正しい照明モデル・反射モデルが使われるが、現実世界をシミュレートするには非常に複雑かつ膨大な計算を伴うため、レンダリングに時間がかかるようになる。はエネルギー保存則をもとに光の伝播を記述するものであり、物理ベースのレンダリングの基本となる理論である。
反射モデルは物体の性質にも左右される。コンピュータグラフィックスにおいて、物体の性質は材質（マテリアル）として定義・抽象化されるが、プラスチックや金属、皮膚や毛髪の質感をコンピュータグラフィックスで正確に再現するためには、それぞれの材質に応じた適切な反射モデルを使う必要がある。物体の色は光のRGB各成分の反射・吸収係数の違いによって生まれ、また鏡面ハイライトの色や形状は面の粗さや光源の特性にも左右される。金属光沢や回折模様を再現する場合は、物質の物理的・化学的特性や表面性状を考慮する必要がある。
また光の屈折現象をコンピュータグラフィックスで再現する場合、物質の特性として屈折率が重要な要素となる。多くの3DCGソフトウェアでは、屈折率 (index of refraction) を略してIORと表記する。
シェーディングとは、物体の陰影を計算することである。広義では反射モデルによる反射光の強度計算を含むが、狭義では後述の陰影補間技法を指す。
ポリゴンモデルから2次元画像を生成する過程での陰影の補間法には次のような種類がある。
隠面消去方法のひとつ。
ポリゴンの座標（大抵は中心点）を基準に、画面の奥（視線からもっとも遠いポリゴン）から、全てのポリゴンを順番に描画する。
後述のZバッファ法のような特殊な処理をせず、基本的に多角形を描画すればよいだけなので、実装が簡単であり、消費メモリが少なく非常に処理が高速にできる利点がある。Zバッファ法が普及するまでは古くは3DCG全般で利用され、また、まで家庭用ゲーム機におけるリアルタイム3DCGでは一般的に利用されていた。しかし、ポリゴン数が増えた場合は、ポリゴンをソートするコストがかかる、またフィルレートが膨大になるため、Zバッファ法と比較して速度的なメリットがなくなる。
ポリゴンが交差した場合に正しく表示することができないという欠点があるが、この解決策として、ポリゴンが互いに交差しないように静的、あるいは動的に細分化する方法がとられることがある。
Zバッファ法と異なり、半透明ポリゴンの描画に関しては、ポリゴンが交差する場合を除いて、概ね正しく扱うことができる。
隠面消去方法のひとつ。
多数のポリゴンが重なった場合、奥のポリゴンが手前に描かれてしまうような不都合が生じることがある。
これを防ぐために、各ポリゴンを描画する際、各画素について視点からの距離を全て記録し、現在記録されている深度よりも近い画素だけを描画する。
Zソート法と異なり、通常は、視点にもっとも近いポリゴンからレンダリングする（Zバッファで判定することで、奥に隠れたポリゴンのレンダリングをスキップできるため）。
Zバッファとは深度を記憶するメモリ領域のことであり、Zバッファ法はアルゴリズムが簡単なためハードウェア化しやすい利点があるが、Zバッファ用のメモリの分だけ、Zソート法よりもメモリは多く消費する。単純に、ピクセル単位で奥行きを判定して、ポリゴンのピクセルを塗るか塗らないかを判定しているだけなので、半透明なポリゴンは、Zバッファ法だけでは正しく処理できない（この場合、一度Zバッファ法で不透明なポリゴンだけ描画し、さらにZソート法で半透明なポリゴンを重ねて描く）。また、互いに接近した平行、あるいは低い角度で交差するポリゴンにおいて、Zバッファに記録される深度の精度によっては、隠面消去が正しく行われない、Zファイティング（Z-fighting）と呼ばれる現象が起きる。
ゲームやCADソフトウェアのプレビュー表示など、リアルタイムでの描画によく利用される。
スクリーンを横一行ごとに分割して、その一行ごとに深度を計算してレンダリングする手法。透過を表現したり、シェーディングと併用することで陰影も表現できる。スキャンラインとは走査線を意味する。比較的高速だが、得られる画像の品質は基本的にレイトレーシングよりも劣る。
レイトレーシングは、視点から光源までの光を追跡することでレンダリングする手法。視点から描画する各画素の方向へ直線を伸ばし、物体と交錯する可否を数学的に判定する。照度は光源との方向ベクトルで計算する。反射と屈折は反射率および屈折率をもとに再帰的に探索を繰り返す。物体との交錯がなくなれば計算は終了する。スキャンラインでは得られない反射や屈折などの表現が可能になる。フォトリアリスティックな画像が得られる反面、大変なレンダリング時間が掛かる。そのため屈折の計算処理については、簡略化あるいは制限を設けるのが一般的である。リアルタイム3DCGの分野では、GPUの発展と共に、レイトレーシングのリアルタイム化が試みられており、Adobe After Effects CCではが採用された。
ラジオシティは、各ポリゴンに光のエネルギー量を持たせて形状の相互反射を計算することで、間接光（やわらかい光の回り込み）などを表現する技術。大域照明（グローバルイルミネーション）の代表例である。計算に膨大な時間が必要になるが、完全拡散面で構成されるシーンでは、一旦物体相互間の光の反射を計算し終えれば、物体や光源が移動しない限り、その計算結果を保存して別のアングルからのレンダリングへ再利用することができる。照明工学の分野で発達した技術を3DCGのレンダリングに応用した。
フォトンマッピングは、光をモデル化したフォトンを光源からばらまいてフォトンマップを作成し、次に作成されたフォトンマップに対し、光線追跡法を適用することでレンダリングする手法。計算量を抑えつつ、物体や媒質の質感や透明感を表現できる。ラジオシティと同様、計算結果の再利用が可能。
通常のレイトレーシングと同様にカメラから視線を飛ばし、オブジェクトと交わった点を始点としてさらに大量に2次視線を飛ばす。ここで得られた色や明るさを平均してその点の色とする。物体表面での光の乱反射を再現できるが、明暗差が大きいシーンではノイズが出やすい。
2次元の画像の最小単位をピクセルと呼ぶのに対し、3次元座標上に取り入れた最小単位をボクセル（voxel）と呼ぶ。多くの3DCGソフトウェアで採用されているのが、物体の表面のみを処理するサーフェスモデルであるのに対して、ボクセルは中身を持ったボリュームモデルである。液体や雲、煙といった流体計算で主に活用されている。では、炎、爆発、溶岩、髪の毛といった表現までも可能にしている。ボクセルモデルでは、正確な形状を作るにはボクセルの密度を上げなければならず、またメモリを大量に必要とする。
医療分野で、患部の状態を表現して、断面図を作成する場合などにも有効である。
レンダリングに必要なオブジェクトを選別し、レンダリングを効率的に処理するために利用されることもある。これをボクセル分割と呼ぶ。
オープンソースプロジェクトでは、OsiriXなど有名である。
衣服を始め、布に関する多くの表現を可能にするための技術。衣服を着たキャラクターの動きや風の影響による布の形状変化のシミュレーションを行ない、デザイナーが手付けで布のアニメーションをつける負担を軽減させる。最終的には、人間の皮膚を始め、あらゆる事象をシミュレーション可能にすることが目指されている。
クロス (cloth) の基本的な考え方としては、質量を持ったメッシュノードを擬似的なバネでリンクさせ、伸縮制限（拘束条件）を持たせることによって、布の伸縮・弾性を再現させる。この質感再現のために、技術者によって様々な計算方法が提案されている。
クロスシミュレーションが大々的に使用された最初の映画を挙げると、ネズミが主役のCG映画『スチュアート・リトル』がある。
キャラクターに衣服を着せる制作手法としては、「擬似的な型紙を作り、結合し、キャラクターに被せる」といったMayaに実装されているClassic Clothと呼ばれる手法と、Syflexのように「普通のモデリングと同様な衣服のモデリングをし、クロスに変換する」という2種類の方法に大別される。
は、MayaもSyflexと同様の方法のnClothという機能が搭載されている。
Syflexはスクウェアによる映画『ファイナルファンタジー』のプロジェクトでジェラール・バネル（Gerard Banel）が開発したクロスシミュレーションをさらに発展させたもの。非常に高速で安定しており、Mayaのように布同士が反発して暴れるようなおかしなシミュレーション結果を出すことは少ない。
リアルタイムの3DCGは科学的なシミュレーションの可視化や、シミュレーターおよび3D CADオペレーションといったインタラクティブ用途に使われる。コンピュータゲーム（テレビゲームやPCゲーム）でも3DCGが一般的になっている。3DCG専用のAPIは主にPCゲームで描画処理を高速化するためにグラフィックスハードウェア（GPU、グラフィックスチップ、ビデオカード/グラフィックスカード）を利用するとき、プログラマが抽象化レイヤーを通してグラフィックスハードウェアにアクセスする方法を提供し、プログラマの負担を軽減する。次のようなAPIはインターフェイスの汎用化が必要となるパーソナルコンピュータやスマートフォンなどのモバイル機器において特によく使われる。
ハードウェアベンダー各社が各々のグラフィックスハードウェア上でこれらの汎用化APIをサポートすることで、同一のプログラムを異なるハードウェア上で動作させることができる。なおゲーム専用機の場合は必ずしも汎用化・抽象化が必要ではないため、各機器ごとに最適化された独自のローレベルAPIが用意されることがほとんどである。
OpenGL 1.5/Direct3D 8.0以降はそれぞれプログラマブルシェーダーをサポートし、プログラマがシェーディング言語によりシェーディング処理をカスタマイズできるようになった。ハードウェア性能の向上に加え、プログラマブルシェーダーによってリアルタイム3DCGの品質は飛躍的に向上した。
そのほか、AMDによるMantleの登場以降は、アップルによるMetal、マイクロソフトによるDirect3D 12、そしてクロノス・グループによるVulkanなど、ゲーム専用機向けAPIのようにハードウェア抽象化の度合いを下げてローレベルなハードウェア制御を可能とする描画効率重視のAPIが出現している。
世界で最も3DCGの研究・実用化が進んだ国はアメリカである。アメリカ計算機学会によるSIGGRAPHの主催など研究での盛んさに加え、ハリウッドの映画産業がバックボーンにあり、計算機科学の先駆研究者達を擁するピクサーなどの制作会社によって3DCGアニメが大量に制作され、実写作品にも盛んに3DCG技術が用いられている。アメリカでの特に重要な研究業績には、アイバン・サザランドによるヘッドマウントディスプレイ（1968年）、エドウィン・キャットマルによるテクスチャマッピング（1974年）やサブディビジョンサーフェス（1978年）、ジム・ブリンによる環境マッピング（1976年）や（1977年）やバンプマッピング（1978年）、ジェームズ・クラークによるジオメトリエンジン（1979年）、による再帰的レイトレーシング（1979年）、ジム・カジヤによるや（1986年）などがある。1995年には初のフル3DCGの長編映画『トイ・ストーリー』が制作された。
フランスのピエール・ベジェはベジェ曲面を考案（1962年）し、はグーローシェーディングを考案（1971年）した。
ベトナムのはPhongの反射モデルやフォンシェーディングを考案（1973年）した。
カナダでは初のフル3DCGのテレビ向け30分枠アニメシリーズとして『リブート』（1994年）が制作された。
フランスでは同じくフル3DCGのテレビアニメシリーズ『インセクターズ』（1994年）が公開された。
デンマークのはフォトンマッピングを考案（1996年）した。
日本の大阪大学大村皓一らはメタボールを実用化（1982年）し、福山大学西田友是らはMichael F. Cohenらとほぼ同時にラジオシティを考案（1985年）した。
コンピュータゲームにおいては、パソコンが主流のため技術革新に対応しやすく、その点ではかつて世界のビデオゲーム産業の盟主だった日本を追い越す結果となった（セガの『バーチャレーシング』、『バーチャファイター』シリーズ、PlayStationなどといった3DCGの採用は早かったものの、専用に近いアーケードゲーム基板や家庭用ゲーム機など数年間は性能が固定されるハードウェアに依存した技術だけが蓄積されてしまったとも言われている）。
日本のアニメでは、劇場版『ゴルゴ13』やテレビアニメ『子鹿物語』（共に1983年）での部分的3DCG導入が世界的にも早かった。ゴルゴ13のCGパートはトーヨーリンクスと大阪大学大村皓一らチームの開発による3DCGシステムで制作されるなど、当時は国産システムの開発が行われていたが、こうした動向は次第に廃れている。国内でのフル3DCG作品では、写実調ではテレビ用映画『VISITOR』（1998年）、アニメ絵調では劇場版『アップルシード』（2004年）が長編作品の端緒に挙げられる。テレビ向けのフル3DCG作品は数分程度の短尺作品が多いが、30分枠テレビシリーズも『SDガンダムフォース』（2004年）の頃から少数ずつ制作されている。
アメリカとは違い、日本ではでもアニメーターによる手描きアニメ作品が主流であり、絵画的な質感やパースに調整された3DCGとの混ぜ使いがみられる。3DCGは背景動画やロボット、群衆シーンなどの作画労力のかかる部分で多く使われるほか、近年ではトゥーンレンダリングの表現力向上により、メインキャラクターでも手描きと3DCGをシーン毎に使い分ける作品（プリキュアシリーズ〈2009年シリーズ以降〉など）が現れている。
