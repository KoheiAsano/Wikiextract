音声認識
音声認識（おんせいにんしき、）とは、人間の声などをコンピューターに認識させることであり、話し言葉を文字列に変換したり、あるいは音声の特徴をとらえて声を出している人を識別する機能を指す。
音声認識とは、人間の声などをコンピューターに認識させることである。話し言葉を文字列に変換したり音声の特徴をとらえて声を出している人を識別したりする機能を指している。
話し言葉を文字列に変換する機能は、指を用いてキーボードから入力する方法に代わるものである。
文字列（文章）を入力する機能だけを呼び分ける場合は「音声入力」あるいは「ディクテーション（聞き取り）」と言う。
（ちょうどキーボードから文字列やショートカットを入力してアプリケーションを操作できるように）音声認識でアプリケーションを操作することも可能である。音声でアプリケーションを操作することは「音声操作」と言う。
「音声認識」に話者が誰なのか識別する機能を含めることもある。これは、あらかじめ記録しておいた音声パターンと比較して個人認証等をおこなう機能であり、この機能を特に呼び分ける場合は「話者認識」とも言う。
音声認識では、統計的手法が良く用いられている。これは大量の発話を記録した学習用データから音声の特徴を蓄積し、認識対象となる入力音声から抽出された特徴と蓄積された特徴とを比較しながら、最も近い言語系列を認識結果として出力する手法である。
一般に、音声の音響的な特徴と言語的な特徴を分離して扱うことが多い。音響的な特徴とは、認識対象の音素がそれぞれどのような周波数特性を持っているかを表したもので、音響モデルと呼ばれる。音響モデルの表現としては、混合正規分布を出力確率とした隠れマルコフモデルが広く用いられている。言語的な特徴とは、音素の並び方に関する制約を表したもので、言語モデルと呼ばれる。例えば、「あなた (a n a t a)」という発声の直後には、「が (g a)」や「は (w a)」などの発声が続く確率が高い、などの制約である。言語モデルの表現としては、認識対象の言語が大規模な場合(パソコン上での文書作成など)はn-gramが良く用いられ、認識対象の言語が人手で網羅出来る程度に小さい場合(カーナビの音声操作など)は、文脈自由文法が良く用いられる。
動的時間伸縮法（、DTW）は初期の音声認識手法であるが、隠れマルコフモデルに基づく手法が一般化したため、使われなくなった。時間または早さの異なる2つの信号シーケンスの間の類似度を測るアルゴリズムである。例えば、人間の歩行のパターンは、素早く歩いても、ゆっくり歩いても、さらには歩行の画像を早送りしてもスロー再生しても一定のパターンが存在する。DTW は音声だけでなく動画などの任意の時系列のデータに適用可能である。音声認識においては、発声速度がどうであっても一定のパターンを検出するために使われていた。従って、比較のための標準パターンが必要であり、認識できる語彙は限定される。
音声信号は、断片的あるいは短時間の定常信号と見ることができ、隠れマルコフモデル（Hidden Markov Model、HMM）が適用可能である。すなわち、10ミリ秒程度の短時間でみた場合、音声信号は近似的に定常過程と見なすことができる。従って、音声を多くの確率過程のマルコフ連鎖と考えることができる。
また、隠れマルコフモデルによる音声認識は自動的にトレーニングされ、単純で計算量もそれほど多くない。音声認識について考えられる最も簡単な設定では、隠れマルコフモデルは10ミリ秒ごとに例えば13次元程度の実数値ベクトルを出力するだろう。このベクトルはケプストラム係数から成る。ケプストラム係数は短時間の信号のフーリエ変換にコサイン変換を使って、その第一（最大）係数を取り出したものである。隠れマルコフモデルは、それぞれの観測されたベクトルの尤度を与える対角共分散のガウス分布の混合ともいうべき確率分布を持つ傾向がある。各単語や各音素はそれぞれ独自の出力分布を持つ。単語列あるいは音素列に関する隠れマルコフモデルは、個々の単語や音素の隠れマルコフモデルを連結したものとなる。
これらが隠れマルコフモデルを使用した音声認識技術の概念である。音声認識システムにはこれ以外にも様々な技術を使用している。語彙の多いシステムでは、音素について文脈依存性を考慮する。また、話者間の違いや録音状況の違いを正規化するために、ケプストラムの正規化が行われる。他にも話者正規化の試みとして、男女間の正規化のための声道長正規化 (VTLN) や、より不特定多数の話者に対応するための最尤線形回帰 (MLLR) がある。
音声認識システムの研究開発にはコンピュータが普及しだした1970年代から21世紀初頭の現在まで、長年にわたって莫大な資金と優秀な人材が投入されてきたが、成功して普及したものはほとんどなく、デジタル技術によって生み出された3次元映像に代表されるアニメーション映画や、動画、静止画、音楽の記録と再生といった技術分野は、その後、大きな産業となっているのと比べれば大きな違いがある。
話者を限定して、「ディクテーション」と呼ばれる事前のトレーニングを行う方式の音声認識システムでは、日本語では理想的な環境下では80%の認識率が達成できるとされている。それらのトレーニングを積まない場合60％が限度である。語彙を限定してトレーニングを必要としないシステムでは、不特定多数の話者の音声を認識できるが語彙が少ないために利用範囲は限定される。
同音異義語が少ない欧米系の言語では90％の認識率があると評価されている 。
個人向けに市販されている音声認識ソフトでは、静かな部屋でユーザーがヘッドセットを使い、単語を区切るなどのいくつかのコツを知っていれば十分実用的な認識率を示す。ただし屋内であっても背後で大声の会話がなされる環境や、屋外などの騒音のある環境では認識が困難である。また、個人のレベルで使用することを想定しているため、対応する語彙が限られ業務用語はカバーされていない。さらに、複数の話者による発声や、音声認識向けと意識していない、例えばインタビューや会議などの発声を認識するのは困難である。
企業向けでは、大規模語彙と複数の不特定話者に対応した会議などの議事録作りに使えるより高価なソフトも販売されており、カセットテープやICレコーダの聞き起こしに比べ効率的に作業を行うことができる。
音声認識システムの性能は一般に正確度と速度で表される。正確度は単語誤り率 (word error rate, WER) で表され、速度は実時間係数 (real time factor, RTF)で表される。
話者の音声の特徴量が雑音や特徴分離処理によって歪むと音響モデルとの差が開いて誤認識の元となる。得られた音声の特徴量に歪みや雑音がどの程度含まれているかを推定し時間軸と周波数軸に対して信頼度をマップとして持たせて、低信頼度の特徴量にはマスクをかけたり、失われた音声を復元する処理に活用するのがミッシング・フィチャー理論（Missing feature theory）
である。
GSS（Geometric source separation）は複数の音源を分離する技術であり、音源間に相関が無ければ複数のマイクからの入力情報によって比較的簡単に音源分離とその位置情報（音源定位）が得られる。これをMFTの雑音情報として信頼度マップに反映させれば、騒音下や同時発話の状況でもそれほど認識率を落とさずに済む。
Windows VistaとWindows 7では音声認識機能が搭載されており、この機能を使用して、キーボード入力なしにチャットをするなどの操作が可能となっている。音声認識機能でパソコンを操作するといった利用方法はこれまでにもあったが、日本語の認識率を向上させているほか、マウスやキーボードで行うWindowsの操作が音声で操作できるようになっている。
Windows 10からはCortanaという音声認識アシスタント機能が搭載され、さらに様々な操作が可能になった。(Windows PhoneではWindows Phone 8.1から搭載されていた。)
企業、病院、自治体では、2005-6年頃から次第に次のような実用システムの導入が活発化してきている。
「感性制御技術」（Sensibility Technology=ST）などと組み合わせることにより、例えば「ごめんなさい」も口先だけで軽く言った「ごめんなさい」も同じ「ごめんなさい」でしかないが、早口で軽いトーンの「ごめんなさい」は、バカにしていると判断して怒った態度で接したり、ゆっくり丁寧に発音された「ごめんなさい」は、心からの謝辞だと理解して許したりすることが可能となる。
