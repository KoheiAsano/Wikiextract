PCM音源
PCM音源（ピーシーエムおんげん）は、コンパクトディスクなどで扱われるパルス符号変調 (pulse code modulation、PCM) 技術を用いたデジタルシンセサイザーの音源方式のひとつ。
あらかじめメモリに記録しておいたPCM波形（サンプル）を再生することで音を生成する装置を示す。電子楽器においてのPCM音源とは、例えば楽器の音などを録音・メモリへ蓄積しておき、鍵盤の押鍵やMIDIのノートオン信号などに応じて所望の音程のPCM波形をメモリから再生する音源方式を示す。1988年にコルグから発売されたシンセサイザーであるM1に採用され、後に電子ピアノやシンセサイザーなどの電子楽器の音源方式のひとつとして広く普及している。
PCM音源はメモリの量が十分あれば任意の波形を発音できることが長所である。対してFM音源やアナログモデリング音源等の他の音源方式と比べ、メモリに収録した波形を変化させることは、単純にボリュームや音階を変化させることを除けば困難であり、シンセサイザーとしての音作りの自由度などでそれら他の音源方式に分を譲る点がある。
PCM音源は楽器メーカーによって独自の名称が用いられることがある。ヤマハのAWM2音源、ローランドのRS-PCM音源、LA音源、コルグのaiスクエアシンセシスやAccess、HIなどと呼ぶ音源方式はいずれもPCM音源である。これらは各社が開発したチップセットや、サンプルの圧縮方法、ひいてはサンプルされた元の音の違い、フィルターの有無等を明示する為の商業用の商標であると考えてよい。
歴史的経緯として、PCM音源方式のシンセサイザーの誕生は、1960年代のコンピュータ制御式電子音楽スタジオ、1970年代のディジタルオルガン開発や、初期のディジタル音楽ワークステーション開発にさかのぼる事ができる。
1960年代初期、イギリス在住のロシア系作曲家 Peter Zinovievは、プライベート電子音楽スタジオ Putney のコンピュータ制御を計画し、技術者のDavid Cockwell（AKAI Sシリーズ設計者）、作曲家の Tristram Caryと共に開発を進め、1967年二台のミニコンDEC PDP-8を導入し、遅くとも1969年には、同年創業のUK法人エレクトロニック・ミュージック・スタジオ（ロンドン）のPutneyスタジオで、「Musys IIIシステム」が稼動した。このシステム上（もしくは後に追加された DOB (Digital Oscillator Bank) も併用）で、世界最初のサンプリングが実現されたと考えられている。EMSと同様なコンピュータ・サンプラーは、後にアメリカでも開発された。1972年創業のComputer Music Inc.の製品「Computer Music Melodian」は、ミニコンDEC PDP-8を中心に、12bit 22kHzのA/DおよびD/Aコンバータ、アンチエイリアス・フィルターを追加した一種のソフトウェア・サンプラーで、1979年スティービー・ワンダーのサウンドトラック「」で使用された。
このように黎明期のPCM音源は、高価なミニコンを駆使した実験装置的な構成だったので、次の段階として、当時民生利用の始まったLSI技術を使った安価なディジタル楽器の実現が開始された。しかし当時米国のLSIビジネスは、金に糸目をつけない宇宙開発・軍事開発を主な顧客としており、民生分野では電卓のような数百万台規模の市場でしか実績がなかったので、市場規模が何桁も小さな楽器分野では、たちまち行き詰るのが目に見えていた。
1969年、ロックウェルのラルフ・ドイチュは、電卓と同様に電子楽器でディジタル革命を起こす計画を立て、アーレン・オルガンと提携してディジタル・オルガンの開発を進めた。そして1971年アーレン コンピュータ・オルガンを発売、1974年子会社RMIからHarmonic Synthesizerを発売した。後者はディジタル倍音加算にアナログ・フィルターを組み合わせた製品で、リアルタイム演算の代わりに計算結果をウェーブテーブル（単周期のPCM音源）に格納して再生する方式が採用された。これら製品の実装技術全てを世界初とするのはかなり無理のある主張だったが、当時は "アポロ計画の技術を使った世界初のコンピュータオルガン" という荒唐無稽な宣伝がなされ、ロックウェルはディジタル楽器の基礎技術全般を囲い込む独占特許の取得に成功した。 提携先のアーレンは訴訟を起こし独占特許を奪取したが、特許買収には巨額な費用を要し、結局、同業他社に次々と巨額な特許使用料請求を行った。この結果、訴訟リスクの高い大手楽器メーカはディジタル楽器開発に消極的になり、代わりに訴訟リスクの小さな研究機関やベンチャー企業が活躍する場を得た。
1975年頃世界各地で、音楽製作をコンピュータ上でシームレスに処理する「ディジタル音楽ワークステーション」の開発が開始された。1979年登場のフェアライトCMIやシンクラビアIIは、サンプラー機能や再合成機能を提供し、1980年のLINN LM-1ディジタル・ドラムマシンや、1982年のイミュレータと共に、初期のサンプリング音楽の流行を形成した。なお登場当時のサンプラーは、音質やサンプリング時間、表現能力に大きな制限があったため、リアルな生楽器の再現は難しく、むしろ音質劣化を音楽的表現として生かす使い方が多かった。こういった初期の制限は、1980年代半ば頃までには大きく改善され、更に演奏トラック全体を取り込んで編集処理する初期のDAW機能がハイエンド環境で提供されはじめた。その後1980年代後半にディジタル楽器全般の低価格化が進み、かつてサンプリングドラム用ROMメーカとして出発したデジデザインやがDAW製品の開発を開始すると、フェアライトは価格より実績や安定性が重視される業務用DAW機器分野に転進した。
1979年頃 PPGの Wavecomputer 340/380は、ウェーブテーブル・シンセシス () と呼ばれる64種の波形を切り替えて音色を変化させる音響合成方式を採用した。また1981年発売のPPG Wave 2.0では、アナログシンセサイザーと同様なフィルタやエンベロープを追加して、ディジタル/アナログ併用のハイブリッド・シンセサイザーを完成した。その後1982年PPG Wavetermではディジタル音楽ワークステーション機能を追加、1986年PPG HDU (Hard Disk Unit) でDAW機能を追加し、同年参考展示のPPG Realizerでは 上記DAW機能に加え、他のシンセ（minimoogやDX7）のソフトウェア・モデリング機能も統合した。しかし1987年PPGは倒産し realizerは商品化されなかった。ハードウェア楽器をソフトウェア的にシミュートするこのアイデアは、後継会社Waldorfと提携先DAWソフト会社 スタインバーグにより、1996年 VST (Virtual Studio Technology)、1998年VSTi (VST instruments) として実現され、現在では広く普及している。
普及価格帯の製品では、1985年Ensoniq Mirage、AKAI S612といった一連の低価格サンプラーが登場し、サードパーティによるサンプリング・ライブラリ提供と合わせ、音色入替え可能なPCM音源として普及した。Ensoniq Mirageはサンプラーながら最初からVCFやVCAを搭載しており、次の製品ESQ-1 は波形テーブル内蔵のハイブリッドシンセだった。Ensoniqはこれ以降もサンプリングに特化する事はなく、サンプルデータや波形テーブルを加工するPCM音源のシンセサイザーを次々と発売した。一方、初期のAKAIサンプラーは録音/編集/再生に特化した「サンプリング機材」だったが、その後シンセサイザー機能やエフェクター機能を取り込んで、複雑な音色作りや繊細な表現が可能な「楽器」へと進化した。1998年Nemsys Gigasamplerは大容量ソフトウェア・サンプラーを実用化し、その後ソフトウェア・サンプラーは数GBのサンプルを駆使して高価な生楽器の音を手軽に再現する「ツール」として現在普及している。
前述のように世界市場では70年代からディジタル楽器が製品化されていたが、国内は一部メーカを除き、ディジタル楽器の研究が決定的に立ち遅れていた。その原因としては、当時国内の電子楽器専業メーカは成長途上だったため、基礎研究投資を行う余力に欠けていた事、逆に体力に余裕のある大手総合メーカ（電器メーカ含む）は、70年代ディジタルオルガン特許訴訟の影響を受け、ディジタル楽器開発に消極的だった事、等が挙げられる。
そのような中、ヤマハは訴訟問題とディジタル音源開発に真正面から取り組み、1980年以降は次々とディジタル音源製品を発売した（ただしPCM音源は問題の特許と抵触する可能性が高かったからか、当初は発売していない）。他方、多くの国内メーカは、80年代半ばに海外メーカが安価な製品を発売するまで (Alesis, Ensoniq, Emu)、本格的なディジタル楽器を一切発売しなかった。
日本におけるPCM音源製品の草分けは、1982年日本ハモンド/Jugg BoxのPCMドラムマシン「DPM-48」と推定される。サンプルは別売りROMで入れ替え可能だったが、発売時期の関係上MIDIには対応していなかった。その後、ローランド/ヤマハ/コルグ/カシオ/テクニクスといった他の国内メーカもPCMドラムマシンを製品化している。
1985年にはAKAI professionalが国産初のサンプラー「S-612」を発売している。このS612は 最大サンプリング周波数32kHzの12bitサンプラーで、サンプリング時間は最長1秒（32kHz時）だったが、音作りに重要なVCFやVCAは内蔵しておらず、同年先行して登場していた Ensoniq Mirageと比較するととてもシンプルな製品だった。その後AKAI Sシリーズは、S900, S1000でスペックと機能を充実させ、80年代後半 - 90年代にはE-muと並ぶ代表的サンプラーに成長した。同シリーズの設計はDavid Cockerell（前期EMSの各製品やElectro-Harmonixディジタルディレイの設計者）、AKAI S1000のOS開発はChris Hugget（EDP WASP/OSC OSCar/Novation SuperNovaの設計者）が担当しており、イギリスを代表する2人のシンセ・デザイナーによる製品と言えるかもしれない。
1987年ローランドはD-50というサンプル・ウェーブをレイヤーできるLA音源方式シンセを発売した。翌年発売されたコルグ社のM1は、サンプルを幾重にも重ねて発音するレイヤー（コンビネーション）機能やVDF（Variable Digital Filter、フィルター）やVDA（Variable Digital Amplifier、エンベロープ）を備えリアルな音と幅広い音作りを特徴とした。このVDFやVDAによって、ただ鍵盤に楽器音を並べて再生するだけにとどまらず、VDFによって音の明るさを調整したり、VDAによって音の立ち上がりやその消え方といったパラメータを変化させたりすることができる。また、ローランドのJV-1080やJV-2080のように拡張カードを差し替えて膨大な音色を扱えるようにした機種もある。
VDFでは、録音された楽器音を削って暗くすることしかできず、VDAで調整可能な時間的変化も限られた範囲での調整となるため、前述の通り音作りの幅が狭い。この点を克服するため、80年代末から90年代の初頭にかけて、シンセサイザーのメーカー各社は工夫を重ねた。ヤマハではFM音源とハイブリッド型のRCM音源を開発し、PCM波形をFM変調できるSY77を発売する。またコルグの01/Wシリーズではウェーブシェーピングという波形を変調できる方法を採用した。また同社のWAVESTATIONシリーズでは、波形を繋ぎ合わせることで時間的に変化できるようにした。そしてローランド社ではアナログシンセイザーと同じように波形を変調できるリングモジュレータを搭載した。また、JD-800のようにアナログシンセサイザーのノウハウを生かした音作りが可能な機種もリリースされた。しかし、90年代後半以後、波形ROMの容量の増加による、PCM音源の音質の向上、そして、様々な奏法の演奏自体を波形として収録可能になったこと、ハイブリッド音源の音作りの難解さなどの理由からヤマハのEX5など一部の機種を除き、このような工夫を施したPCM音源のシンセサイザーは姿を消していった。
家庭用ゲーム機におけるPCM音源は、スーパーファミコンの64kバイトやメガCD及びプレイステーションの512kバイトなど、サウンド用のメモリ容量の少なさという厳しい制約がついてまわるため、波形の時間的な変化などは苦手としており、原始的なシンセサイザーと同様に、音量や音高の変化を（時に擬似的な）モジュレーションやエンベロープなどに依存する事で、楽音の表現力を補完している事が多かった。例外として、アーケードゲームの一部は膨大な容量をPCM波形に割いている場合もあるが、90年代のPCM音源黎明期においてはメモリ容量も小さく高価であった為、コストのかかる手法であった。なお、楽器としての使用ではなく、単純な音声の再生（セリフの発音など）に関しては、PCM音源のバッファを一時バッファとして使い、DMA転送で連続してデータを送り込みながら再生することで、バッファ容量以上の時間の音声の再生を実現することが多かった。一方でDVDメディアなどからストリーミング再生をするときには容量の制約はほぼなくなるが、ローディング時間増などのデメリットがある。家庭用ゲーム機の多くは、この2種類を用途により使い分けている。
携帯電話の着メロや着うたについても、PCM音源、またはADPCM音源が採用されているものの、着メロの場合、パケット課金が存在する為に、端末に搭載できるメモリが大きくなった現在でも、着メロとしてFM音源とあわせて原始的なシンセサイザーとして配信される場合がある。
減衰の早い音では「ワンショット」と呼ばれる通常のサンプリング、及び再生が行われるが、減衰の遅い、もしくは減衰の無い音を用いる場合、メモリーの使用量が膨大となる。この場合、アタック部分が過ぎた後、安定した波形をループさせることで、メモリー使用量を大幅に削減することが可能である。またこの場合、エンヴェロープなどを併用し、より自然な音を構成することが求められる。ある程度長い時間単位でループさせる場合もあれば、波形1周期を基準にループさせる場合もある。前者の場合はより自然に音を繋ぐため、波形を厳選した上で、クロス･フェードを行う場合もある。後者の場合はメモリーは大きく節約できるものの、一般に表情が乏しくなるため、各種パラメータを変更することで、音に表情を付けることが必要とされる。
