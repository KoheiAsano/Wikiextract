オペレーティングシステム
オペレーティングシステム（、OS、オーエス）とは、コンピュータのオペレーション（操作・運用・運転）のために、ソフトウェアの中でも基本的、中核的位置づけのシステムソフトウェアである。通常、OSメーカーが組み上げたコンピュータプログラムの集合として、作成され提供されている。
オペレーティングシステムは通常、ユーザーやアプリケーションプログラムとハードウェアの中間に位置し、ユーザーやアプリケーションプログラムに対して標準的なインターフェースを提供すると同時に、ハードウェアなどの各リソースに対して効率的な管理を行う。現代のオペレーティングシステムの主な機能は、ファイルシステムなどの補助記憶装置管理、仮想記憶などのメモリ管理、マルチタスクなどのプロセス管理、更にはGUIなどのユーザインタフェース、TCP/IPなどのネットワーク、などがある。オペレーティングシステムは、パーソナルコンピュータからスーパーコンピュータまでの各種のコンピュータや、更にはスマートフォンやゲーム機などを含む各種の組み込みシステムで、内部的に使用されている。
製品としてのOSには、デスクトップ環境やウィンドウシステムなど、あるいはデータベース管理システム (DBMS) などのミドルウェア、ファイル管理ソフトウェアやエディタや各種設定ツールなどのユーティリティ、基本的なアプリケーションソフトウェア（ウェブブラウザや時計などのアクセサリ）が、マーケティング上の理由などから一緒に含められていることもある。
OSの中で、タスク管理やメモリ管理など特に中核的な機能の部分をカーネル、カーネル以外の部分（シェルなど）をユーザランドと呼ぶ事もある。
現代の主なOSには、Microsoft Windows、Windows Phone、IBM z/OS、Android、macOS（OS X）、iOS、Linux、FreeBSD などがある。
OSの主な目的は、ハードウェアの抽象化、リソースの管理、そしてコンピュータ利用効率の向上である。
OSはアプリケーションソフトウェアを動作させるのが第一の目的である。このためのインターフェースがAPI（アプリケーション・プログラミング・インタフェース）とABI（アプリケーション・バイナリ・インタフェース）である。カーネルはシステムコールによってアプリケーションにサービスを提供する。さらに基本ライブラリも含めた形でアプリケーションに対してAPI/ABIを提供する。アプリケーションによってはOS上のミドルウェアやアプリケーションフレームワークなどをAPIとして使用する場合もある。
APIはプログラミングのためのインターフェースであり、プログラムを作成する際の規則を構成する。例えば、C言語での関数やFORTRAN/Pascalなどのライブラリ呼び出しの仕様といったものがそれにあたる。
一方、ABIはコンパイルされたソフトウェアがOSの機能を呼び出す際のインタフェースであり、プロセスが動作する際の規則を構成する。例えば、Unix系のOSはAPIがほとんど共通だが、ABIはOSによって異なる。したがって、同じCPUを使ったシステムであっても、ABIが異なれば実行ファイルが異なる。ABIには、呼出規約、システムコールの方法などが含まれる。
なお、OSの垣根を越えたABIもいくつか存在する。例えば、OCMP (Open Computing Environment for MIPS Platform) というMIPS系チップを使用したUNIX機によるバイナリ共通インタフェースが日本電気やソニー、住友電気工業、日本タンデムコンピューターズなどにより定義され、その定義に沿ったUNIX-OSが複数販売された。
ファームウェアとデバイスドライバの助けを借り、カーネルはコンピュータの全ハードウェアデバイスの基本的制御を提供する。RAM上のプログラムのメモリアクセスを管理し、どのプログラムがどのハードウェア資源へのアクセスを得るかを決定し、常に運用が最適化されるようCPUの状態を設定し、ファイルシステムと共にディスク、磁気テープ、フラッシュメモリといった長期的不揮発性記憶装置でのデータの編成を行う。
OSはアプリケーションプログラムとコンピュータハードウェアの間のインタフェースを提供し、OSに組み込まれた規則や手続きに従うことによってアプリケーションプログラムはハードウェアとやりとりできる。OSはまた、アプリケーションプログラムの開発と実行を簡素化するサービス群も提供する。アプリケーションプログラムの実行にあたって、OSのカーネルがプロセスを生成する。プロセスの生成には、メモリ空間などの資源の割り当て、マルチタスクシステムでのプロセスへの優先度の割り当て、プログラムのバイナリコードのメモリへのロード、アプリケーションプログラムの実行開始といった仕事が含まれる。そうして初めてユーザーやハードウェアデバイスとやりとりを開始できる。
割り込みはOSの要であり、OSが周囲の環境と相互作用し反応するための効率的手段となっている。非常に小さなスタック（50バイトや60バイト）しか持たない古いシステムでは、OSが対応しなければならないイベントの発生源を「監視」するポーリング方式を採用していたが、現代の大きなスタックを持つシステムでは一般的ではない。現代の多くのCPUは、割り込みをベースとしたプログラミングを直接サポートしている。割り込みが発生すると、その時点のレジスタコンテキストを退避し、そのイベントに対応した特定のコードを実行する。非常に基本的なコンピュータにもハードウェア割り込み機能があり、プログラマは特定の割り込みが発生したときに実行すべきコードを設定することができる。
割り込みを受信すると、コンピュータのハードウェアは実行中のプログラムを自動的に一時停止させ、状態を退避させ、その割り込みに事前に割り当てられているコードを実行する。これは例えば読書中に電話が鳴ったとき、本にしおりを挟み、電話に出るのに似ている。現代的なOSでは、割り込みはOSのカーネルが扱う。割り込みはコンピュータのハードウェアが発生させる場合もあるし、実行中のプログラムが発生させる場合もある。
ハードウェアから割り込みが発生した場合、OSのカーネルがそのイベントにどう対応するかを一般に何らかの処理コードを実行して決定する。割り込みには優先順位があり、それに従って実行するコードが決定される。再び人間にたとえれば、電話が鳴ると同時に火災を知らせる火災報知器の非常ベルも鳴ったら、電話には出ずに避難するだろう。ハードウェア割り込みの処理は通常、デバイスドライバと呼ばれるソフトウェアに委任される。デバイスドライバはOSのカーネルの一部という場合もあるし、別のプログラムという場合もあるし、混在する場合もある。デバイスドライバは割り込みによって得た情報を各種手段を通じて動作中のプログラムに中継する。
実行中のプログラムがOSに対して割り込みを発生させる場合もある。例えば、あるプログラムがハードウェアにアクセスしたい場合、OSのカーネルに対して割り込みを発生させ、結果として制御をカーネルに移す。するとカーネルは必要な処理を行う。また、プログラムがメモリなどの資源を追加で要求する場合、割り込みを発生させてカーネルに知らせる。ただし、それらは一般にシステムコールと呼ばれ、ハードウェア割り込みとは実装が異なることもある。
現代的CPUには複数の運用モードがある。その場合、少なくともユーザーモードとスーパーバイザモードの2つが存在する。スーパーバイザモードはOSのカーネルが使用するモードで、ハードウェアに無制限にアクセスでき、メモリの読み書きの方法を制御したり、グラフィックスカードなどのデバイスとやりとりしたりできる。一方ユーザーモードはカーネル以外のほぼ全てが使用する。アプリケーションはユーザーモードで動作し、ハードウェアとのやりとりはカーネルを通す必要がある。CPUは2つ以上のモードを持つこともあり、古いプロセッサをエミュレートするのに使ったりする。
コンピュータが起動した際は、自動的にスーパーバイザモードで動作する。BIOSやEFI、ブートローダー、OSのカーネルといったごく一部のプログラムがスーパーバイザモードで動作する。このようになっているのは、ユーザーモードの環境の初期化はその外側にあるプログラムでないと行えないためである。しかし、OSが他のプログラムに制御を渡す際には、CPUをユーザーモードに設定できる。
ユーザーモードでは、プログラムが使用できるCPUの命令セットが制限されている。ユーザープログラムでユーザーモードを抜け出すには、割り込みを発生させ、カーネルに制御を戻す。そのようにしてハードウェアやメモリへのアクセスといったことへの独占的制御をOSが保持している。
パーキンソンの法則によると、「メモリを拡張するとプログラムはそれに伴って拡大する」という。プログラマーは無限の容量と無限の速度のメモリを理想としている。コンピュータのメモリは階層構造になっていて、最も高速なレジスタから、キャッシュメモリ、RAM、最も低速なディスク装置がある。OS内のメモリ管理部はこのようなメモリを管理するもので、利用可能な部分、割り当てと解放、主記憶と二次記憶との間でのスワップなどを制御する。
マルチプログラミングOSのカーネルはプログラムが使用中の全システムメモリの管理責任を負っている。それによってあるプログラムが既に別のプログラムが使用しているメモリを誤って使用しないようにしている。プログラム群は時分割で動作するので、それぞれのプログラムの独立したメモリアクセスが可能となっている。
協調的メモリ管理は初期のOSでよく使われた方式で、全プログラムが自発的にカーネルのメモリ管理機構を使い、割り当てられたメモリをはみ出さないように動作することを前提としている。プログラムにはバグがつきもので、そのために割り当てられたメモリからはみ出すこともあるため、このようなメモリ管理は今では見られない。プログラムが異常動作すると、他のプログラムが使用中のメモリを書き換えることもあった。悪意あるプログラムやウイルスが意図的に他のプログラムのメモリを書き換えたり、OS自体の動作を妨げたりすることも可能である。協調的メモリ管理では、たった1つのプログラムがおかしな動作をするだけでシステム全体がクラッシュする。
カーネルによるメモリ保護により、プロセスのメモリへのアクセスが制限される。メモリ保護には様々な技法があり、セグメント方式とページング方式が代表的である。どの技法でも何らかのハードウェアサポートが必要であり（例えば、80286のMMUなど）、あらゆるコンピュータがそのようなハードウェア機構を備えているわけではない。
セグメント方式でもページング方式でも、CPU内のユーザーがアクセスできないレジスタ群でユーザープログラムがアクセス可能なメモリアドレスの範囲を設定している。その範囲外のアドレスにアクセスしようとすると割り込みが発生してCPUがスーパーバイザモードに遷移し、カーネルがその状況に対処する。これをセグメンテーション違反と呼ぶ。セグメンテーション違反は一般にプログラムの間違いから発生するので、実行を継続するような対処は困難であり、カーネルは問題のプログラムを強制終了させ、エラーを報告するのが一般的である。
Windows 3.1 から Windows Me までは何らかのメモリ保護機構を備えていたものの、それを回避するのも容易だった。そのためセグメンテーション違反の発生を知らせるが考案されたが、それでもシステムがクラッシュすることが多かった。
ページングやセグメントによる仮想記憶を使用することで、カーネルは任意の時点で各プログラムが使用するメモリを選択でき、同じメモリ位置を複数タスクで使用させることも可能となる。
あるプログラムが使用可能な現在のメモリ範囲だが物理メモリが割り当てられていない位置にアクセスしようとしたとき、セグメンテーション違反のように割り込みによってカーネルに遷移する。このような割り込みをUnix系ではページフォールトと呼ぶ。
カーネルがページフォールトを受け付けると、そのプログラムに割り当てられた仮想メモリ空間の調整を行い、要求されたメモリアクセスが可能になるよう物理メモリを割り当てる。これにより、カーネルはそれぞれのアプリケーションへのメモリ割り当てを自由に決定でき、さらには実際には割り当てないでおくことも可能となる。
現代的OSでは、相対的にアクセス頻度が低いメモリを一時的にディスクなどの二次記憶装置に退避させ、主記憶を他のプログラムのために空けることができる。これをスワッピングと呼び、限られたメモリを複数のプログラムで使用可能にし、メモリの内容を必要に応じて退避させたり復帰させたりできる。
仮想記憶により、実際に搭載しているよりも多くのRAMを使用しているかのような感覚でコンピュータを使用することができる。
コンピュータ上の各動作はバックグラウンドであっても一般のアプリケーションであっても、内部的にはプロセスとして動作する。DOSのような機能の限定されたOSは一度に1つのプロセスしか実行できない。近代的なOSは一度に複数のプロセスを動作させることができる（マルチタスク）。プロセス管理は複数のプロセスを実行するためにOSが行う処理である。プロセッサを1つだけ持つ一般的なコンピュータでは、マルチタスクは高速にプロセスからプロセスへ切り替えを行うことで実現される。ユーザーがより多くのプロセスを実行すれば、個々のプロセスに割り当てられる時間は少なくなっていく。多くのシステムでは、これが音声の途切れやマウスカーソルの奇妙な動作などを引き起こす。一般的なプロセス管理は、プロセスごとに優先度を与え、それによって配分される時間を決めている。
OSのカーネルにはスケジューラと呼ばれるソフトウェアが含まれており、プロセッサが実行すべきプロセスの順序と一度に実行する期間を決定している。スケジューラが選択したプロセスにカーネルが制御を渡し、それによってそのプログラムがCPUとメモリにアクセス可能になる。その後何らかの機構で制御がカーネルに戻され、スケジューラが再び新たなプロセスを選択する。このようなカーネルとアプリケーション間の制御の切り替えをコンテキストスイッチと呼ぶ。
プログラム群へのCPU時間の割当方法の初期のモデルとして協調的マルチタスクがある。このモデルでは、カーネルがあるプログラムに制御を渡すと、そのプログラムは時間を制限されることなく処理を行え、カーネルには自発的に制御を戻すことになっている。したがって、悪意あるプログラムやバグのあるプログラムがあると他のプログラムにCPU時間が割り当てられなくなり、無限ループに陥っている場合はシステム全体がハングアップする。
プリエンプティブ・マルチタスクでは、動作中のプロセスから任意の時点で制御を奪うことができ、全プログラムに所定のCPU時間を割り当てることが可能である。これを実現するためOSはタイマ割り込みを使用し、所定の時間が経過したら割り込みを発生させてスーパーバイザモードに制御を戻させ、カーネルがスケジューラを呼び出す。
現代的OSでは、プリエンプションの考え方をユーザーモード（アプリケーション）だけでなくデバイスドライバやカーネルコードに対しても適用し、リアルタイム性を向上させている。
ホームコンピュータなどのシングルユーザーOSでは、少数のよく評価されたプログラムしか使わないことが多く、協調的マルチタスクで全く問題ない。例外として AmigaOS は初期のバージョンからプリエンプティブ・マルチタスクを実現していた。Microsoft Windows で初めてプリエンプティブ・マルチタスクを実装したのは Windows NT だが、それが一般家庭向けに発売されるのは Windows XP からだった。
ディスクに格納したデータへのアクセスは、あらゆるOSの中心的機能である。コンピュータはファイルという形でディスクにデータを格納する。ディスクの内容は高速アクセス、高信頼性、ディスク領域の利用効率などを考慮して編成される。このファイルをディスクに格納する方式をファイルシステムと呼び、それによってファイルに名前と属性が付与される。また、ディレクトリあるいはフォルダと呼ばれる構造を使い、ファイル群を階層構造（木構造）内に格納できる。
初期のOSは一種類のディスク装置しかサポートしておらず、ファイルシステムも一種類ということが多かった。初期のファイルシステムは容量や性能が低く、ファイル名やディレクトリ構造の面で制約が多かった。そういった制約はOS自体の設計上の制約を反映していることが多く、複数のファイルシステムをサポートするのもOSの制約の観点から非常に困難だった。
より単純なOSではストレージへのアクセス手段が限られているが、UNIXやLinuxなどのOSでは仮想ファイルシステム (VFS) という機構をサポートしている。UNIXなどのOSは様々なストレージデバイスをサポートしており、それらの仕様やファイルシステムとは独立した共通のアプリケーションプログラミングインタフェース (API) でアクセスできるようにしている。そのためプログラムはアクセスしようとしているデバイスに関する知識を持つ必要がない。VFS機構により、プログラムはデバイスドライバとファイルシステムドライバを経由してシステム上のあらゆるデバイスと様々なファイルシステムにアクセス可能となる。
ハードディスクドライブなどの補助記憶装置には、デバイスドライバを通してアクセスする。デバイスドライバは担当するデバイスのインタフェースをよく理解しており、それをOSが全ディスクドライブに共通で用意しているインタフェースに変換する。UNIXでは、それがブロックデバイスのインタフェースである。
Linuxを元プラットフォームとして開発されたものにはext2、ext3、ReiserFSなどがある。また、他のプラットフォームからXFS、JFS、FATファイルシステムなどが移植され、NTFSも不十分ながら読み書きが可能である。
Macintoshではまず最初にMacintosh File System (MFS) が実装されたが、ディレクトリ機能を備えていなかったためファイルブラウザFinderでフォルダをエミュレーションしていた。その後Hierarchical File System (HFS) でディレクトリ機能を実装し、現在は改良を加えたHFS+が採用されている。現在macOSで読み書きが可能なものはHFS、HFS+、UNIX File System (UFS)、FATとなる。なおUFSの使用は一般でなく、FATへの対応は他プラットフォームとのデータ交換に用いられる。NTFSは読み込みのみが可能であり、書き込みについてはCommon Internet File System (CIFS) によるネットワークを介したものに限られる。
Windowsが標準で扱えるファイルシステムは、FAT、FAT32、NTFSである。NT系のWindowsではNT3.51まではOS/2標準のHPFSにアクセス可能だった。現在Windows上ではNTFSが最も信頼性と効率が高いものとして一般的に利用される。FATはMS-DOSから採用される古いファイルシステムであるが、パーティションやファイルサイズに制限があり、大容量化したハードディスクではあまり用いられない。このためファイルサイズの制限をなくしたexFATが新たに開発された。なお、exFATはVistaや7では標準で使えるが、XPでexFATを使うためには専用のプログラムを新たにインストールする必要がある。
FATはその仕様の制限から大容量のハードディスクには向かないが、その一方構造が単純でデジタルカメラや携帯電話などの組み込みシステム向けを含むさまざまなOSで読み書き可能なことから、各種メモリカードやUSBメモリなどプラットフォームを跨ぐ用途においては主流である。なお、それらフラッシュディスクの大容量化に対応するため、マイクロソフトはFATを拡張したexFATというファイルシステムを発表している。
MacintoshからWindows等へファイルを転送すると、転送先のWindows側に本体とは別のファイルが出現することがある。これはHFSやHFS+のみがサポートするリソースフォークと呼ばれるデータ構造によるもので、Macintoshではそれらを一元的に管理を行うため一つの書類に見える。このように幾つものフォークを一つのデータに格納することをマルチフォークと呼び、もとのデータを改変することなくOS独自の管理情報を容易に付与できる機能だが、実質的にMacintoshでしか利用できない。
ファイルシステムには、急な電源切断などによる障害へ対応する機構を持つものがある。
ジャーナルファイルシステムが最もよく採用される機構であり、その他にもZFSのように書き込み操作をトランザクションとして扱うものもある。これらを用いることで、障害復旧時のチェックを大幅に短縮する、または完全に不要にする。一方これらの機構を持たないファイルシステムでは、ファイルシステムの整合性を保つためストレージ全体を検査する必要がある。
デバイスドライバはハードウェアとのやり取りをするためのソフトウェアである。一般にハードウェアとの通信を行うインタフェースを持ち、ハードウェアの接続される何らかの通信サブシステムやバスを経由して通信を行う。コマンドをハードウェアに送り、データの送受信を行う。また、一方でOSやアプリケーションに対するインタフェースも提供する。ハードウェアに強く依存するプログラムであり、OSにも依存している。これによって、OSやアプリケーションがハードウェアを使って動作することが容易になっている。ハードウェアの非同期的な割り込みの処理もデバイスドライバの役割である。
デバイスドライバの主たる設計目標は抽象化である。ハードウェアは用途が同種のものであっても、機種によって動作や性能などがそれぞれ異なる。新たな機能や性能を提供するハードウェアが登場したとき、それらは従来とは異なった制御方式を採用していることが多い。OSを将来にわたってあらゆるハードウェアを制御できるように設計するのは困難である。従って、個別のハードウェアの制御をOSから切り離す必要がある。デバイスドライバはOSとのインタフェース（関数呼び出し）をデバイス固有の処理に変換することが主たる機能となる。理論的には、新たな制御方法の新しいハードウェアが登場しても、そのハードウェア用のドライバが古いOSに対応していれば、古いOSでもドライバだけ置き換えればハードウェアを制御可能となる。
Vista以前のWindowsやバージョン2.6より以前のLinuxカーネルでは、ドライバ実行は協調的だった。すなわち、あるドライバが無限ループに陥ると、システム全体がフリーズした。その後のバージョンではプリエンプションが可能となり、カーネルがドライバを中断させることができるようになった。
多くのOSはTCP/IPプロトコルをサポートしている。歴史的に見れば、初期のコンピュータネットワークはモデムを使って電話回線で行われていた（BSC手順など）。その後、パケット通信が使われるようになり、IBMのSNAなどの各社独自のネットワークアーキテクチャが登場した。現在では、TCP/IPを中心とした通信が主流となっている。
通信プロトコルは、トランスポート層まではカーネル内モジュールとして実装し、プレゼンテーション層より上はシステムプロセスとして実装されるのが一般的である。セッション層の実装はシステムによって異なる。
このようなネットワーク機能により、異なるOS間でネットワークを形成し、計算能力 (RPC)、ファイル、プリンター、スキャナーなどのリソースを共有できる。ネットワークにより、あるコンピュータのOSが遠隔のコンピュータにあるリソースをあたかも自身に直接接続されているかのように透過的に利用できる。単純な通信に始まり、分散ファイルシステム、グラフィックスやサウンドといった機能の共有まで様々な応用がある。透過的アクセスの例としては、SSHによるコマンドラインの直接使用などもある。
OSが関係するセキュリティ機能は、ユーザーがリソースへの何らかのアクセスを行う際に前もって認証し、そのユーザーのアクセスレベルを決定し、管理者の方針に基づいてアクセスを制限することである。
OSは、処理を許可すべき要求と処理すべきでない要求を識別できなければならない。一部のシステムは単にユーザー名などで要求者を識別し、それによって特権の有無を判断する。要求者を識別する過程を「認証」(authentication) と呼ぶ。ユーザー名を示さなければならないことが多く、ユーザー名に続いてパスワードも必要な場合がある。別の認証方法として、磁気カードや生体データを使った「認証」(certification) を行うこともある。ネットワーク経由に接続などの場合、認証を全く行わずにリソースにアクセスさせることもある（ネットワーク上で共有されたファイルを読む場合など）。
さらに高度なセキュリティを備えたシステムでは、監査証跡 (auditing) オプションも提供している。これは、リソースへのアクセス要求を監視し記録するものである（「このファイルは誰が読もうとしたか?」など）。プログラムが何らかのリソースを要求すれば割り込みによってカーネルに制御が渡るので、そこでセキュリティの確認が可能である。プログラムがハードウェアやリソースに直接アクセスできる場合、セキュリティは確保されない。
何者かがコンソールやネットワーク接続経由でログインしようとする際にもセキュリティの確保が必要である。このような要求は一般にデバイスドライバ経由でカーネルに渡され、それから必要ならアプリケーションに渡される。ログインにまつわるセキュリティは、企業や軍などで機密情報を保持しているコンピュータでは長年の課題だった。アメリカ国防総省 (DoD) はセキュリティ評価に関する基本要件を定めた標準 "Trusted Computer System Evaluation Criteria" (TCSEC) を策定した。TCSECはセキュリティを要求されるシステムの調達条件とされるようになったため、OSメーカーはこれを重視するようになった。
個人が使用するコンピュータにはユーザインタフェースが必要とされる。ユーザインタフェースは必ずしもOSの一部とは限らない。通常はシェルなどのプログラムが実装しているが、人間とのやりとりが必要なプログラムは基本的にユーザインタフェースを備えている。ユーザインタフェースは、キーボードやマウスやクレジットカード読み取り機といった入力デバイスからのデータを取得するのにOSを介する必要があり、モニターやプリンターといった出力機器にプロンプトやメッセージを出力するのにもOSを介する必要がある。主なユーザインタフェースは、古くからあるキャラクタユーザインタフェース（コマンドラインインタフェース）と視覚的なグラフィカルユーザインタフェースに大別される。
最近のOSは一般にGUIを持っている。多くのプロプライエタリなシステム（Windows やMac OS）はカーネルとGUIが密接に関係している。他のOSではユーザインタフェースはモジュール化されていて、任意のGUIをインストールしたり、新たなGUIを作成したりできる（Linux、FreeBSD、OpenSolaris）。
Windowsでは新たなバージョンが登場するたびにGUIを変更してきた。初期のWindowsからWindows Vistaまでを比べてみると、その変化は大きいし、MacintoshのGUIは1999年のMac OS Xの登場で劇的に変化した。
Macでは初期からSystem 6.0.xまでが白黒のGUIで、System 7以降もカラー化されたのみで、Mac OS 8でプラチナアピアランスが採用されても、Mac OS 9.2.2までは基本要素はほぼ変わらなかった。しかしMac OS Xになって完全に刷新され、AquaベースのGUIになった。Mac OS X v10.3以降ではメタルアピアランスが導入され、その後もバージョンアップのたびに少しずつ手が加えられている。また、Aquaとは別にX11も用意されている。
Mac OS Xの前身のNEXTSTEPは様々な独創的なGUI要素で知られ、他のOSやデスクトップ環境に大きな影響を与えた。グレースケールのシステムだったころよりアルファチャンネルを備えていたのは特筆すべき点である。
Linuxでは、GUIを提供するデスクトップ環境がいくつか存在する。Linuxで使えるGUIとして有名なものは、GNOMEとKDEがある。
1950年代、OSという概念が登場し始めた。初期のコンピュータはOSを持たなかった。しかし、システム管理用ソフトウェアツールやハードウェアの使用を簡素化するツールはすぐに出現し、徐々にその利用範囲を拡大していった。最初のOSは、IBM 701用にゼネラルモーターズが開発したもの、IBM 704用にゼネラルモーターズとノースアメリカン航空が共同開発したもの等、多くの候補があるが、どういった機能が搭載された時点でOSと呼ぶかによる。この時代のものをOSとは呼ばない場合もある。
当時は、パンチカード等から入力されたプログラムを磁気テープに一旦保存し、その磁気テープを大型コンピュータに接続後、プログラムをロードして実行していた。そのため、入出力装置のドライバに当たるものが作成されていた。また、アセンブラやコンパイラが登場し始めた時代なので、まずコンパイラをロードしてからプログラム（ソースコード）をロードし、コンパイル結果として出力されたアセンブリ言語をアセンブルするために、さらにアセンブラをロードするといった手続きが必要だった。こうした作業を自動化するバッチ処理がOSの機能として実現されていた。また、プロセスの状態を監視するモニタも実装されていた。
1960年代前半には、OS機能の増強が進められた。スプール、ジョブ管理、記憶保護、マルチプログラミング、タイムシェアリングシステム、そして、仮想記憶の概念が登場し始めた。これらの概念を複数搭載するOSも登場していた。また、マルチプロセッシングシステムに対応するOSもあった。
1960年代後半には、OSは著しい進化を遂げた。現在のOSの概念や基本部分（カーネル）の技術の大半は、この時期に完成された。
1962年、ゼネラル・エレクトリックがGECOS(後のGCOS)の開発を開始した。
1964年のIBM System/360シリーズに搭載されたOS/360は世界初の商用OSとされ、単一のOSシリーズで幅広いモデル（性能、容量、価格帯）と周辺機器を稼働させ、更にハードディスクドライブをサポートし、本格的な（プリエンプティブな）マルチタスクを実現した。「オペレーティングシステム」という用語が一般化したのもOS/360からである。従来は機種ごとに専用の制御ソフトが付属し「機種が変わればプログラムは書き直し、周辺機器は買い直し」が常識だったが、OSがアプリケーションに一貫した上位互換のAPIを提供する事で、OS/360用に書かれたプログラムは、40年以上経過した現在のz/OS上でもバイナリ互換で動作する。
この頃のもう1つの重要な進歩としてタイムシェアリングシステムの本格的な実用化がある。コンピュータの資源を複数のユーザーが並行的に使えるようにすることで、システムを有効利用するものである。タイムシェアリングは、各ユーザーに高価なマシンを独占しているかのような幻想を抱かせた。1965年のMulticsのタイムシェアリングシステムは特に有名である。更に1967年にはSystem/360用に、商用初の仮想化OS（仮想機械）であるCP-40とCP-67が登場し、1台のコンピュータで同時に複数のOSを稼働できるようになったが、これもタイムシェアリングの応用である。
また仮想記憶は1961年のバロース B5000が商用初とされ、1970年のIBM System/370シリーズ用のOS/VSで広く普及した。コンピュータの利用形態としてオンライントランザクション処理やデータベース処理が普及したのもこの頃である。
1970年代～1980年代前半は、多種多様な分散システムが普及した。ミニコンピュータ用OSとしては、VMSが有名である。Multicsは1970年代の様々なOS、UNIXなどに影響を与えた。UNIXはオープンシステムと呼ばれ、ミニコンピュータからメインフレームまで広く普及した。
また1970年代には低価格なマイクロプロセッサが登場したが、初期のマイクロコンピュータは、メインフレームやミニコンピュータのような大規模なOSを搭載する容量もなかったため、ディスク管理程度の必要最低限の機能しか持たないOSが開発された。初期の特筆すべきOSとしてCP/Mがあり、8ビットのマイクロコンピュータで良く使われた。その大雑把なクローン（複製）として16ビットのIBM PC用にPC DOSが生まれ、そのOEM版であるMS-DOSが普及した。これらはOSの提供する機能が少なく、画面制御など多くの機能は、アプリケーションが直接ハードウェアを操作する必要があったため、同じCPUを使用していても、ハードウェア（機種）が異なると互換性も失われた。このMS-DOSと後継のMicrosoft Windowsによって、マイクロソフトは世界有数のソフトウェア企業となった。
なお、1980年代の別の特筆すべき流れとして、GUIを標準装備したアップルコンピュータのMacintoshがある。MacintoshのOS (Mac OS) は、当時の性能的制約から、多くの部分がファームウェアの状態でハードウェアに組み込まれてはいたが、現在でいうウィジェット・ツールキットを含むToolboxと呼ばれるAPI群を持ち、アプリケーションにおけるGUIのデザイン開発をある程度まで標準化した。
マイクロプロセッサの高性能化と低価格化が進むと、業務用途のシステムでは、高機能な端末を大量に用意することが可能になり、UNIXをベースとしたクライアントサーバモデルが普及した。クライアント機であるワークステーションのOSとしてSunOS、IBM AIX、IRIXなどのUNIX系OSが用いられた。この時期には肥大化したUNIXの再設計の機運が高まり、マイクロカーネルという新しい設計手法が生まれ、成果としてMachなどのカーネルが作られた。しかし、UNIXの権利を持つAT&Tがライセンスに厳しい条件をつけるようになり、UNIXを自由に改変したり、改変した機能を外部に公開することができなくなった。このため、オープンシステムとしてのUNIXのオープンな文化は一時衰退に追い込まれた。さらにUNIXの標準規格を巡ってUNIX戦争が勃発し、UNIX市場は大きなダメージを受けた。
1980年代後半には、パソコンにも32ビット時代が到来し、1990年代に入ると、低価格なAT互換機でもメモリを十分に搭載すればPC-UNIXの利用が可能になりはじめた。当時のパソコンでは、OSとして最低限の機能しか持たないDOSが依然として使われており、GUIやネットワーク、マルチメディアに対応させるため、ベンダがDOSを様々な形で拡張したシステムソフトウェアや、ウィンドウシステムを搭載するようにもなったが、これは互換性や信頼性など様々な点で問題を発生させていた。こうした問題を解決するため、堅牢な（プリエンプティブな）マルチタスク機能、高度なネットワーク機能など、従来のUNIX(互換)ワークステーション並みの機能がパソコンにも求められるようになってきた。さらに、肥大化したソフトウェア開発の効率を改善するためにオブジェクト指向APIを導入し、Macintoshのように標準化されたGUIを備えることも求められた。これらの機能を備えたOSは「次世代OS」、「モダンOS」などと呼ばれた。
1987年にはIBMとマイクロソフトが、パーソナルコンピュータ用に堅牢なマルチタスク機能・GUI（同年末の1.1より）・ネットワーク機能（拡張版）を装備したOS/2を発表した。1988年に登場したNEXTSTEPは、業務用途に耐える堅牢性・全面的なオブジェクト指向導入による柔軟性・高度なグラフィック機能・一貫したGUIといった、新世代のデスクトップOSで求められる機能を全て実現した。しかしこれらは当時のハードウェア性能では負荷が大きかったため広くは普及せず、代わりに、軽量だが堅牢なメモリ管理やマルチタスク機能は持たないMac OSや、Windows 3.x などのGUI環境が徐々に普及していった。これらは当時の限られたハードウェアでも快適に動作したが、安定性や機能では劣っていた。
UNIX（互換）系OSの流れでは、UNIXの権利を持つAT&T（1992年からはノベル）がソースコードの自由な改変を禁じていたことから、オープンソースのUNIX互換OSが開発されはじめる。1990年にHurdの開発が開始され、1991年に、Linuxがフリーソフトウェアとして公開された。マイクロカーネルなどの新しい設計手法を採用し、トレンドに合わせたびたび設計が変更されたHurdの開発が停滞する一方、Linuxは保守的な設計とバザール方式という不特定多数の担い手による開発手法を採用し、迅速な開発が進められ、PC-UNIXのデファクトスタンダードとなった。ただしLinuxはOSの心臓部であるカーネルのみのため、カーネル以外のOSを構成するソフトウェアを揃えて自ら環境を整える必要があり、初期段階においては技術者などのごく一部の人たちにのみ使われていた。386BSDを皮切りにフリーのBSD系UNIXも登場したが、UNIXの権利者だったノベルとBSDを開発したカリフォルニア大学バークレー校との訴訟に巻き込まれ、開発中止を余儀なくされた（1994年からFreeBSDとNetBSDの開発が再開される）。
1994年には、Windowsとしては初めて、32ビットに本格対応（カーネルの32ビット化）し、堅牢なマルチタスク機能を備えたWindows NTが登場した。ただこれも負荷や互換性の問題などから個人用途にはあまり普及せず、Windows 3.xを拡張しつつ、Windows NTの機能を限定的に取り入れたWindows 9x系との並存が続いた。WindowsがWindows NTベースに一本化されたのは2001年のWindows XPからである。
また、アップルも同年、NEXTSTEPを発展させたMac OS Xを新たにリリース、従来のMac OSの後継となった。このころには低価格なパーソナルコンピュータでも、これらのOSの負荷を問題としないほどに高性能化しており、オープンで低価格な分散コンピューティングを広めた（ダウンサイジング）。
2003年にはパソコンにも64ビット時代が到来し、OSも64ビット化が進んだが、16ビット化や32ビット化の際と比較するとOSの機能や役割に大きな変化はなかった。商用のパソコンOSを二分するWindowsとMac OS Xのいずれもが64ビットへの移行を徐々に進めていった。Windowsは同一バージョンのOSで32ビット版と64ビット版の双方を提供して、Mac OS Xは32ビットカーネルを維持したまま、一般プロセスに64ビット機能を持たせる道を選んだ。2000年代中頃まではパソコンの性能向上が著しかったため、デスクトップ用途の新しいオペレーティングシステムは同時代における高性能なパソコンを必要としていたが、2006年を境にしてCPUの性能向上の限界が顕著に現れ始めると、高効率化を目指した開発にシフト。Windows Vista・Windows 7やmacOSなどの新OSにおいて、高機能のマルチコアCPUやプログラマブルシェーダを搭載したビデオチップへの対応が進められた。
オープンソースの流れでは、従来よりGNUがUNIX向けのツール群を開発していたが、これらをLinuxカーネルと組み合わせたGNU/Linuxシステムが、2000年頃よりUnix系OSの主流となった。またBSD系OSもUNIX系OSのシェアの大きな部分を占めている。
一方、組み込みシステムにもより複雑な機能が求められるようになり、NetBSD、VxWorks、LynxOS、QNX、Enea OSE、Symbian OSなど汎用OSをベースとしリアルタイム性能を持たせた組み込みオペレーティングシステムが幅広い用途に使われている、中でもITRONを含むTRON系OS・APIが、2016年現在、組み込みOSの60%のシェアという。
1990年代以降はダウンサイジングの流れにより、業務用途でもオープンシステムやWindowsへと主流が移行している中、信頼性・可用性を重視する用途には、現在でも専用OS（z/OS、MSP(Multidimensional System Products)/XSP、VOS3、ACOSなど）を搭載したメインフレームが採用され、使い分けられている。
2000年代末以降、パーソナルコンピュータ市場が成熟化する一方で、スマートフォンやタブレットに代表される、デスクトップOSから派生した組み込みプラットフォームが普及し、モバイルコンピューティングが一般化した。
これらはカメラ、GPS、加速度センサー、ジャイロスコープ、無線LAN、Bluetooth、狭い画面に最適化されたタッチパネルなどのインターフェースを組み込み、携帯機器の低消費電力の要求に応えたiOS、Androidなどのモバイルプラットフォームを採用している。
主なOS別シェアの調査結果は以下であった。
