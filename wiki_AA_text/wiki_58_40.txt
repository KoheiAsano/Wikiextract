スーパーコンピュータ
スーパーコンピュータ（）は、科学技術計算を主要目的とする大規模コンピュータである。日本国内での略称はスパコン。また、計算科学に必要となる数理からコンピュータシステム技術までの総合的な学問分野を高性能計算と呼ぶ。スーパーコンピュータでは計算性能を最重要視し、最先端の技術が積極的に採用されて作られる。
普及価格帯の計算機の性能では実行不可能な超大規模な計算処理が目的であり、それを実現するための特別な構造(極端に大量のCPUコアを搭載する,超大容量のメモリを搭載するなど)を備えたハードウェアやハードウェアに最適化されたソフトウェアを備える。有限要素法や境界要素法などに基づく構造解析、気象予測、分子動力学、シミュレーション天文学、最適化問題、金融工学のような大規模数値解析に基づくシミュレーションに利用される。計算機による大規模シミュレーションを前提とした科学は特に計算科学と呼ばれ、スーパーコンピュータの設計に大きい影響を与えている。そのような計算科学の成果を元に、工業製品の設計や評価を行うCAEの分野でも広く利用されている。
一部のスーパーコンピュータでは、高速な処理を実現するためハードウェアやソフトウェアはその計算用に特化して作られることがある。そのような場合、スーパーコンピュータを別な目的、すなわち汎用的な演算に用いるのには適さない。また、入力する値やフォーマットを揃えておくような制約が生まれることもある。スーパーコンピュータ本体の開発に加えて、これらを間断なく生成して送ることができる効率のよいアルゴリズム開発も重要な要素である。加えて、高速化に伴い省電力化を含む電力効率の対処、排熱と冷却の方法の開発も重要な要素技術となっている。
スーパーコンピュータの定義は時代に沿って大きく変化してきているが、一般的にはその時代の最新技術が投入された最高クラスの性能の計算機を指す。現時点では一般的に使用されるサーバ機よりも浮動小数点演算が倍以上の速さのコンピュータを「スーパーコンピュータ」と呼ぶことが多い。Cray-Iが登場したときには、メインフレームの30倍程度であった。
日本の政府調達に関する規程では、中央政府などの一部の機関に対して、理論的最高性能値が50<ruby lang="en">TFLOPS<rp>（</rp><rt lang="en-Kana">テラ・フロップス</rt><rp>）</rp></ruby>以上のスーパーコンピューターを、「政府調達手続に関する運用指針」の手続に従って調達することを求めている。
スーパーコンピュータは、高度な演算を必要とする計算処理に使用され、その計算処理には量子力学、天気予報、気象研究、計算化学（構造体、化合物、生物学上の高分子、ポリマー、結晶などの性質の計算）、物理的なシミュレーション（航空機の風洞シミュレーション、核兵器の爆発シミュレーション、核融合の研究）などがある。特に国家プロジェクトと呼ばれるものでは、完全な解決のためには非常に莫大な計算資源を要求するものもある。
なお、「計算能力によるコンピューティング」と、「計算容量によるコンピューティング」は、関連はあるものの異なるものである。「計算能力によるコンピューティング」は、典型的には「大きな問題を最大のコンピューティングパワーを使用して最短時間で解決する」考え方であり、あるシステムでは解決できるサイズや複雑さの問題は、他のコンピュータでは解決できない。しかし「計算容量によるコンピューティング」は対照的に、大小の問題を解決したりシステムの稼動準備をするために、コンピューティングパワーを効率的な費用対効果で使用する考え方である。
スーパーコンピュータといえども、プロセッサ、メモリ、ストレージ、ネットワーク等のハードウェアと、その上で動くオペレーティングシステム（OS）やアプリケーションなどのソフトウェアから構成される点では一般的なコンピュータと同じである。しかし、それら各要素には高性能計算を実現するためにさまざまな新技術が投入されている。その新技術の中には後に一般的なコンピュータに導入されたものも多数ある。なおスーパーコンピュータのユーザは、本体とは別に用意された端末や、SSH・telnet経由で操作を行う。
スーパーコンピュータに搭載されるプロセッサの役割も、普通のコンピュータ同様に計算処理を行うことである。
一般的なコンピュータと（最近の）スーパーコンピュータの大きな違いは、処理を並列に実行する点にある。通常の単純なプロセッサは、一命令あたり一つの演算だけを行うスカラープロセッサで、一般的なパーソナルコンピュータ（PC）に搭載されるプロセッサ数も1つかごく少数である。スーパーコンピュータでは、1クロックで複数の演算を一度に行うベクトル演算などを備えたプロセッサの採用や、システムの中に数十個から数十万のプロセッサを搭載し計算を同時に実行することで高いスループットを実現する構造となっている。
ベクトル演算が1970年代に実装された後も、1980年代には並列処理、パイプライン処理、投機的実行、対称型マルチプロセッシング、1990年代にはVLIW、SIMDなどがスーパーコンピュータに導入され、並列度の向上を実現した。
スーパーコンピュータで最初に採用された技術の多くは、その後にサーバやPCにフィードバックされて、それらの性能向上に寄与した。またその逆に、それまでPC向けであったx86プロセッサが21世紀に入ってから、価格性能比の向上と超並列技術の向上により、スーパーコンピュータの構成に広く採用されるようになった。
1980年代から90年代までは、高性能計算に特化した専用のベクトルプロセッサを各スーパーコンピュータメーカーが独自に開発し、システムに採用していた。
1990年代前半から、i860、Alpha、POWER、MIPS、SPARC、IA-64などのワークステーションやサーバ向けの汎用プロセッサが、組み合わされるメモリーが安価なこととあいまって徐々にスーパーコンピュータにも導入され始め、90年代後半では一部のハイエンドなものを除いて汎用プロセッサベースのシステムが主流となった。そのようなシステムはコンピュータ・クラスターとも呼ばれ、プロセッサを多数搭載することで高いスループットを狙っている。
さらに、21世紀からのx86プロセッサの価格性能比の向上に合わせ、インテルやAMDのCPUを採用するメーカーが増加している。x86の流れをくむx86-64アーキテクチャを含めると2010年6月に発表された第35回TOP500ランキングでは500台中450台がx86プロセッサを採用しており、PowerPCを含むPOWERベースのシステムと共に市場を二分しつつある。
汎用プロセッサが主流となった90年代後半以降になっても、特に高性能なシステムではベクトルプロセッサによるものが多かったが、それも21世紀に入り変化した。2002年に運用が開始され以降2年半に渡ってTOP500の首位を占めた地球シミュレータのような例外はあるものの、ハイエンドな分野でも置き換えが進行し、2010年6月のランキングにおけるベクトル計算機は500台のうち1台のみとなっている。
特定の計算を支援するコプロセッサや本来画像処理のために開発された<ruby lang="en">Graphics Processing Unit<rp>（</rp><rt lang="en-Kana">グラフィックス プロセッシング ユニット</rt><rp>）</rp></ruby>（GPU）を汎用的な計算に利用する"GPGPU" (General Purpose computing on GPU）など、ある用途に特化したプロセッサをスーパーコンピュータに活用する動きがある。汎用プロセッサに比べ、価格性能比が非常に高くまた消費電力が小さいという利点によって、特に2005年以降動きが活発になってきている。
GRAPEプロジェクトでは、1989年から多体問題に特化したプロセッサを製作し、天文学や分子動力学シミュレーションにおいて非常に価格性能比の良い専用計算機を開発している。
東京工業大学のTSUBAMEにはOpteronによる約1万個のCPUコアの他に、ClearSpeedによる高性能計算専用アクセラレータCSX600が搭載されている。2006年11月のランキングでCSX600を利用することで、2006年6月に発表されたCPUのみの結果に比べ約10TFLOPS性能が向上した。
また、高性能GPUを手がけるAMD、NVIDIAは両社とも2007年に汎用計算を念頭に置いたGPUベースのアクセラレータを発表している。
また、このGPGPU利用の流れを受け、経済指標予測・リスク計量などの膨大なシミュレートと計算が必要である経済予測分野において、多くの経済研究機関・シンクタンクに向け、アメリカや台湾の複数のベンチャー企業がGPGPUベースの高速予測システムを提供しつつあり、経済分野での貢献も始まっている。
スーパーコンピュータはノードと呼ばれる計算機の集合によって構成され、その計算機はコンピュータネットワークによって接続される。そのノード間を結ぶコンピュータネットワークのことを特にインターコネクトと呼ぶ。超並列マシンでは、ユーザの実行させたい処理を各ノードに分割して実行し、MPI等のAPIを使ったノード間通信で同期や計算結果の集約などを行う。そのため、高い性能を得るには広帯域かつ低遅延なインターコネクトが必要とされる。
旧来のスーパーコンピュータの多くでは独自のインターコネクト方式を採用しており、2007年現在 CrayはRapidArrayと呼ばれる独自方式を自社のシステムに採用している。コンピュータ・クラスターでは、イーサネットやInfiniBand、Myrinetなど、最大数十Gbps程度の帯域を持つインターコネクトが利用されている。
研究レベルにおける通信速度は2005年11月にIBMの研究所による14GB/chが最高速であったが、2006年3月現在、NECおよび理化学研究所による次世代HPC構想の研究にて25GB/chが記録されている。
スーパーコンピュータにおけるインターコネクトでは、そのトポロジも性能に大きい影響を与える。よく用いられるネットワークトポロジとしては、メッシュ、クロスバー、トーラスなどがある。構築にかかるコストやアプリケーションの性質によって、システムに適切なネットワークトポロジは大きく異なる。
1970年代前半のCrayによるスーパーコンピュータ黎明期から、オペレーティングシステムにはUNIXおよびLinuxなどのUnix系が広く使用されている。この理由には、当初はライセンスフリーなオープンソース的なOSであったこと、主にC言語で書かれており機種間の移植が容易なこと、大学や研究所で広く使われており科学技術計算用のライブラリやツールが充実していること、などが挙げられる。
2000年頃よりUnix系であるLinuxの比率が急増し、2009年現在では約9割である。
なお、x86プロセッサの急激な価格性能比の向上を踏まえ、マイクロソフト社はWindows Serverをベースとしたスーパーコンピュータ向けOS（WCCS）を2006年6月にリリースした。採用例には東京工業大学がある。2008年9月には後継製品としてを発表し、これを採用したのスーパーコンピュータが2008年のTOP500で11位に躍り出るもこれがWindowsマシンでは最高の成績であり、2015年11月時点でゼロにまで減っており、OSは依然としてUnix系が大多数である。
各Unixで通常使われているスケジューラだけでなく、優先度の高い計算処理にCPU資源を強制的に割り当てるギャング スケジューリング方式もサポートしたものが多い。
スーパーコンピュータの性能を引き出すためには、それが持つハードウェアの特性に合わせてアプリケーションを開発する必要がある。スーパーコンピュータ向けアプリケーションの開発で利用される技術・手法を以下に示す。
科学技術計算分野ではFortranが古くから使われ、コンパイラ最適化技術が成熟していることやアプリケーション・数値演算ライブラリなどのソフトウェア資産の蓄積が大きいことから2017年現在でも利用される。実行効率と開発効率の面から、C言語およびC++もよく用いられる。
開発効率の改善とハードウェアの並列度向上に対応するため、新たなプログラミング言語が提案されている。サン・マイクロシステムズは、2007年1月に科学技術計算向けプログラミング言語Fortressを発表し、オープンソースとして公開している。他にもＩＢＭ社のX10などいろいろな提案がある。
高い性能を求められるスーパーコンピュータ向けアプリケーションでは、ベクトルプロセッサのベクトル演算命令やSIMDなどの並列演算命令を活用し、並列度を高めることで性能向上を図っている。具体的な手法として、最適化コンパイラが並列実行可能な箇所を発見し自動並列化を行うベクトル化や、プロセッサの並列演算命令をプログラミング言語の拡張機能やアセンブラを使い、プログラム内で明示的に呼び出す方法などがある。
2013年現在主流であるコンピュータ・クラスター型のスーパーコンピュータでは、MPIを用いて、プログラマがプロセス間の通信や同期をプログラムに記述することで大規模な並列計算を行う方法が一般的である。スーパーコンピュータ向けベンチマークLINPACKの一実装であるHPLや、遺伝子の相同性検索を行うBLASTなど多くの科学技術計算アプリケーションでは、MPIを用いた並列化に対応している。
分散コンピューティングの発展系として、遠隔地のスーパーコンピュータを含めたネットワーク上の多数のコンピュータを統一的に利用する手段として、グリッドコンピューティングの技術開発が世界的に進められており、日本でもNAREGIが国家プロジェクトとして採択を受け、研究と構築が行われている。また、国内の学校を含む、研究・教育機関に教育用に導入されているPCにグリッド基盤パッケージを導入し、現時点では利用されていないCPU資産をグリッドコンピュータの一部として活用する計画への参加を呼びかけている。グリッドコンピューティングの走りとして世界中のPCが参加しているSETIやグリッドによる分散処理に向いた研究素材を集めて、共通のグリッド基盤で処理を進めるBOINC、World Community Gridといったプロジェクトが軌道に乗っており、世界各国のプロジェクトが相乗りして成果を挙げている。
グリッド・コンピューティングの特徴は、ノードとして参加している個々のクライアントが自由にリソースの稼働率を決められる点にあり、稼働中のクライアントはパフォーマンスを提供する。一方、クラウド・コンピューティングは、リソースの管理をサービスプロバイダに委ね、クライアントは単にサービスを受けるのみであり、この点ではスーパーコンピュータを補完する機能はない。しかし、増加する一途の演算量とそれを保管するストレージの管理も分散コンピューティングの重要な要素になっており、クラウドを構築しておくことで、たとえネットワークが分断されても各ノードが演算すべきデータを見失わないようすることが可能となる。
歴史的には、その時点で最高速のコンピュータ、特に科学技術計算で必要な浮動小数点演算が重視されたコンピュータが、「スーパーコンピュータ」と呼ばれ、主として軍事用に使われる事が多かった。1960年代にはCDC、1970年代にはクレイが、ベクトル演算を中心としたスーパーコンピュータでシェアを伸ばし、また各種シミュレーションなどで民間の需要も拡大した。1980年代にはNECなどの国産メーカーが海外にも進出し、日米スパコン貿易摩擦にも発展した。これらベクトル型は巨大・高価であって特殊専用の度合いが高いため「巨艦主義」と呼ばれることもある。
しかし1990年代後半からは、安価なx86やPOWERなどの汎用プロセッサを大量に使用して並列処理を行うスカラー型のスーパーコンピュータの性能が向上し、TOP500でも上位を占めるようになった。またスカラー型は小型化も容易なため、中小の企業や研究所などへ科学技術計算の市場を広げている。
2010年代には中国のスーパーコンピュータが世界一の速度を獲得できるまでに台頭するようになった。
2016時点でのスーパーコンピュータベンダは、中国の国家機関、レノボ、曙光 (Sugon)、日本のNEC、日立、富士通と、アメリカのIBM、HPE、SGI、クレイ、およびそれらの派生品を扱う欧州ベンダであるBullなどがある。（SGIは2006年5月に連邦倒産法第11章の適用を申請し受理されたが、2006年11月に第11章適用対象から外れ再生を果たした。2016年にはHPEがSGIを買収すると発表した。）
スーパーコンピュタの出荷台数トップ5は、HPE、レノボ、クレイ、曙光、IBMの順である。日本のベンダについては、作成するスーパーコンピュータの台数は少なく、海外への販売実績のあるNECのSXシリーズ以外は国内利用向けが主である。TOP500の上位50位内には、自社での検証機と国策のNLS用スーパーコンピュータがランクインしている。
スーパーコンピュータの性能比較や、スーパーコンピューティングの技術を評価する賞として有名なものには以下のものなどがある。
スーパーコンピュータの性能比較はTOP500ランキングが広く知られている。TOP500は評価基準にベンチマークのLINPACKを使用し、世界で最も高速なコンピュータの上位500位を発表している。LINPACKは主にプロセッサの演算性能のピーク値を測定するもので、異なる時代や異なる設計思想のコンピュータ間を含めて比較しやすいが、低価格な汎用プロセッサを多数搭載して並列処理を行うスカラー型のスーパーコンピュータが上位を占めやすく、目的とする個々の業務における使い易さや実際の処理性能を示すものとは限らない。
より実際の業務における評価基準を目指したものにはHPCチャレンジベンチマークなどがあり、一般的な科学技術計算で多用されている複数のベンチマークから構成されており、4部門の1位がHPCチャレンジ賞（HPCC）として発表されている。
またスーパーコンピュータのエネルギー消費効率を評価するプロジェクトにはGreen500があり、電力当たりの性能を評価基準にして上位500位をランキングしている。性能値はTOP500の結果を使用して、消費電力はコンピュータ本体の測定値を使用している。
また大規模データ処理の処理性能を競うGraph500がある。
スーパーコンピューティングの成果に対する賞には、研究成果に対するゴードン・ベル賞や、研究者に対するシーモア・クレイ賞やシドニー・ファーンバック賞などがある。
世界各国でもスーパーコンピュータの導入は進んでおり、1990年代初頭のような日米を2極とした導入数の集中状況は解消しつつある。アメリカも日本もスーパーコンピュータによるシミュレーション能力が国際競争力の源泉であることに気が付き、次々と次世代スーパーコンピュータ構想の手を打っている（詳細は京 (スーパーコンピュータ)を参照）。さらに、日米両国はそれぞれの政府主導の下、各省単位でのHPC投資促進が続けられており、数十PFLOPSコンピュータを2010年までに構築する計画が複数進んでいる。
日本におけるスーパーコンピュータの流れは、官学主導による国策としての大型スーパーコンピュータ構想と、産業界及び産学協同のより実生活や一般的な産業面に近いスーパーコンピュータの利用や設置の流れがある。この2つの流れの間で産官学での調整が行われており、トップダウン型にはWebクライアント技術、ASIC、マイクロプロセッサ）など、ボトムアップ型には通信インフラストラクチャー、プロトコル、規格化などがある。
文部科学省が推進する日本の科学技術政策では、国立大学や国立研究機関などへのスーパーコンピュータの導入に関して、以下のNLSとNISという位置付けがされている。
例えば、数値風洞（1993年11月のTOP500で首位）やPACSのCP-PACS（1996年11月のTOP500で首位）はNLSとして使用が始まり、その後2年ほどでNISとして利用された。2004年まで2年半の長期に渡ってTOP500の第1位を占めた地球シミュレータもNLSとして開発され、2007年頃からはNISとして供用された。
2009年11月、長崎大学の浜田剛助教らがゴードン・ベル賞（価格性能部門）を受賞した。市販のGPU 760個の並列処理により、単精度による多体計算において、国内最速の地球シミュレータ2（倍精度LINPACKベンチマークでの測定値122.4 Tflops）を上回る158 Tflops を開発費用3800万円で実現した。
浜田助教は「高性能の計算機は重要」としながら「（巨費を投じた従来の開発方針は）素直にいいとは言えない。方向性が逆」と発言した。GPUを大量に繋げるプログラムの開発が成功のカギとされた。
2010年11月のTOP500では東京工業大学のTSUBAME 2.0が4位を獲得した。同時期1位中国NUDTの天河一号Aと同様GPUを大幅に採用しているのが特徴であり、開発費は約30億円である。（天河一号Aは約80億円。2002年世界一の地球シミュレータが600億円）。
2009年11月、日本で唯一ベクトル型を続けているNECは、インテルとのXeonを使用したスカラー型スーパーコンピュータの共同開発計画を発表した。
日本はスーパーコンピュータの省エネ化にも取り組んでおり、2013年11月21日に公開された省エネ性能ランキングでは、東京工業大学のTSUBAME-KFCが、2位に2割以上の差を付けて1位を獲得した。
2006年より文部科学省は、地球シミュレータに代わる次期 NLS として、「次世代スーパーコンピュータプロジェクト」を開始した。当初計画ではベクトル・スカラー複合機を開発して、「2012年に 10ペタFLOPS」を達成し、実質的にTOP500の1位を目指す内容であった。
しかし2009年2月にアメリカで「2011年に20ペタFLOPS」を目標とするセコイアが発表され、予定通りとなれば「日本の1位奪還」にはならない見込みとなった。2009年5月にはNEC・日立が経営不振を理由に同プロジェクトから撤退し、3社によるベクトル・スカラー複合型から、富士通単独によるスカラー型へ設計変更された。
同年11月13日には行政刷新会議の「事業仕分け」で、当プロジェクトは「予算計上見送りに近い縮減」（事実上の凍結）と判定されたため多数の議論が行われたが、政府は判定を見直し、12月16日には2010年度予算に227億円の計上を決定した
構築途上ながら2011年6月の時点において、LINPACKベンチマークの実行性能8.162ペタフロップス、実行効率93.0％を達成。2位と比べて3倍以上の実行性能を発揮し、TOP500の1位を獲得した。さらに2011年11月2日、最終構成を用いたLINPACKベンチマークの実行性能が10.51ペタフロップス（実行効率93.2%）となり、世界で初めて実行性能10ペタフロップスを超えるコンピュータとなった事を発表した。セコイアは計画より一年遅れて2012年になって稼働し、京の性能を上回った。
ビッグデータと呼ばれる膨大な情報の処理に関係する国際的なスパコン性能ランキング「グラフ500」では、2015年2期連続で世界1位を獲得した。
さらに京の次期システムとして、京の100倍程度高速なシステム（１エクサプロップスのシステム）を構築することが検討されている。
国策巨大プロジェクトには、従来より多数の議論が存在するが、主な論点には以下がある。
地球シミュレータによるコンピュートニクショックの後、その潜在的に大きな科学技術と国力・軍事研究の粋を挙げてHPC技術の更改と続伸を続けており、2006年8月現在、TOP500のランキングの上位50%以上をアメリカのスーパーコンピュータが占めている。近年の米国の計算機開発は、のためのコンピュータシミュレーションや高信頼性代替核弾頭など各種兵器の開発設計、作戦シミュレーションなど軍事利用が多く、技術開発は国防総省国防高等研究計画局とエネルギー省国家核安全保障局核備蓄管理プログラム（先端シミュレーション・演算プログラム）の開発プロジェクトや研究費に担うところが大きい。国立科学財団（NSF）、国立衛生研究所（NIH）、航空宇宙局（NASA）などもスーパーコンピュータの設置や研究開発への資金提供を行っている。HPC技術は民間用スーパーコンピュータとしても生命科学、金融工学、VFX・コンピュータグラフィックスなど広範な分野で使用されている。
2014年11月現在、主な計画には以下がある（現在1位はオークリッジ国立研究所に設置されたタイタンの17ペタフロップス）。
欧州各国においては、元々1980年代からスーパーコンピュータのハードウェア分野には敢て手を出さず、シミュレーションソフトやコンパイラなどのソフトウェア開発に力を注いでいた。次世代スーパーコンピュータに関しても、アメリカや日本のより良い部分を選択・取得し、得意のソフトウェアに注力した発展と一般化したスーパーコンピュータの普及を目指して動いている。また近年の情報社会・メディア総局の方針では、ミドルウェア開発を念頭に置いたプロジェクトを中心とすることとなっている。
1990年代は非常に少なかったが、中華人民共和国・台湾・大韓民国・インド・マレーシアといった国々では、スーパーコンピュータ購入や自国での構築も行っており、TOP500 クラスの新規案件が増えている。
他
